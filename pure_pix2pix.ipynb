{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# My Pure Pix2Pix Implementation\n",
    "\n",
    "****\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## General Presets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\"\"\" Import Packages \"\"\"\n",
    "\n",
    "# Numerical Operations\n",
    "import random\n",
    "import numpy as np\n",
    "# Reading/Writing/Cleaning Data\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import gc\n",
    "# For Progress Bar\n",
    "from tqdm.auto import tqdm\n",
    "# For Display\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb as wb\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset, random_split\n",
    "from torchvision.datasets import DatasetFolder, VisionDataset\n",
    "# my_utilities\n",
    "import my_utilities\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-10T16:15:56.865365Z",
     "end_time": "2023-10-10T16:16:07.893262Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mcullencatniss\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011277777777932999, max=1.0â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bea0eb3420004ecb8f11cbecc86fe303"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.12"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>D:\\CAMPUS\\AI\\Essays\\PIX2PIX&CycleGAN\\pytorch-CycleGAN-and-pix2pix_fork\\wandb\\run-20231010_161615-1th8t57x</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/cullencatniss/pure_pix2pix/runs/1th8t57x' target=\"_blank\">run0</a></strong> to <a href='https://wandb.ai/cullencatniss/pure_pix2pix' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/cullencatniss/pure_pix2pix' target=\"_blank\">https://wandb.ai/cullencatniss/pure_pix2pix</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/cullencatniss/pure_pix2pix/runs/1th8t57x' target=\"_blank\">https://wandb.ai/cullencatniss/pure_pix2pix/runs/1th8t57x</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/cullencatniss/pure_pix2pix/runs/1th8t57x?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x129b996ac50>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" For Display \"\"\"\n",
    "\n",
    "plt.style.use(r'C:\\Users\\chael\\.matplotlib\\violet.mplstyle')\n",
    "wb.init(project=\"pure_pix2pix\", name=\"run0\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-10T16:16:07.900250Z",
     "end_time": "2023-10-10T16:16:37.681363Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\"\"\" For Auto-reload Modules\"\"\"\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-10T16:16:37.631836Z",
     "end_time": "2023-10-10T16:16:38.239771Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\"\"\" Assure Reproducibility \"\"\"\n",
    "\n",
    "seed=29\n",
    "my_utilities.assure_reproduce(seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-10T16:16:38.241772Z",
     "end_time": "2023-10-10T16:16:39.478720Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configurations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\"\"\" Path & Device\"\"\"\n",
    "\n",
    "dataset_name = 'facades'\n",
    "task_name = 'facades_pix2pix'\n",
    "data_dir, checkpoints_dir , results_dir = 'datasets/'+dataset_name, 'checkpoints/'+task_name, 'results/'+task_name\n",
    "device=my_utilities.register_device()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-10T16:16:39.477721Z",
     "end_time": "2023-10-10T16:16:40.147788Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\"\"\" Loading & saving Rules \"\"\"\n",
    "\n",
    "# 'data_load_threads' =\n",
    "# 'epoch_load' =\n",
    "model_load = 'by iters.' # | by_epochs\n",
    "results_save = 5000 # frequency of saving latest result (by iters.)\n",
    "checkpoints_save = 5 # frequency of saving latest checkpoints (by epochs)\n",
    "model_save = 'by iters.' # | by_epochs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-10T16:16:40.144781Z",
     "end_time": "2023-10-10T16:16:40.689532Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\"\"\" Preprocessing Rules \"\"\"\n",
    "\n",
    "preproc = {\n",
    "    'trans': 'scale & crop', # | crop | scale width | scale width & crop | none\n",
    "    'scale_size': 286, # !!! in TEST TIME set to crop_size !!!\n",
    "    'crop_size': 256,\n",
    "    'flip': False, # whether to flip images in augmentation\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-10T16:16:40.692533Z",
     "end_time": "2023-10-10T16:16:41.311093Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "\"\"\" Model \"\"\"\n",
    "\n",
    "model_name = 'pix2pix'\n",
    "translate_dirct = 'facades->photo' # | 'photo->facades'\n",
    "\n",
    "hyper_params = {\n",
    "    # ======= network architectures =======\n",
    "    'G_arch': 'U-net256', # | U-net128\n",
    "    'D_arch': 'PatchGAN', # (for experiments in the paper) | PixelGAN | StdCNN\n",
    "    # 'G_layers':\n",
    "    'D_layers': 3,\n",
    "    'in_chan': 3,\n",
    "    'out_chan': 3,\n",
    "    'G_fil_lst': 64, # num. of filters in G's last conv. layer\n",
    "    'D_fil_fst': 64, # num. of filters in D's first conv. layer\n",
    "    'batch_size': 32,\n",
    "    'norm_type': 'instance', # (for experiments in the paper) | batch | none\n",
    "    'G_dropout': False, # no dropout for G in the paper\n",
    "    'D_dropout': True,\n",
    "    # ============== training ==============\n",
    "    # 'init_type':\n",
    "    'init_scaler': 0.02, # scaling factor for weight initialization\n",
    "    'shuffle_batch': True,\n",
    "    'continue_train': True, # whether to load latest model\n",
    "    'loss_mode': 'vanilla GAN', # | lsgan | wgangp\n",
    "    'L1_lambda': 100, # L1's scaler (add L1 to GAN-loss according to the paper)\n",
    "    'beta1': 0.5, # momentum for Adam (0.9?)\n",
    "    # 'beta2': (?)\n",
    "    'lr': 0.0002, # initial learning rate for Adam (0.001?)\n",
    "    'lr_dec_mode': 'linear', # | step | plateau | cosine\n",
    "    'lr_dec_iters': 50, # multiply by a gamma every lr_decay_iters iterations\n",
    "    'init_lr_epochs': 100,\n",
    "    'decay_lr_epochs': 100, # linear decay to 0\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-10T16:16:41.292840Z",
     "end_time": "2023-10-10T16:16:41.781139Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============CONFIGURATIONS============\n",
      "Device = cuda\n",
      "Model is loaded by iters.\n",
      "Model is saved by iters.\n",
      "Model = pix2pix\n",
      "Translation Dirct. = facades->photo\n",
      "--------------------------------------\n",
      "Transforms Opt. = scale & crop\n",
      "Img. Scale Size = 286\n",
      "Img. Crop Size = 256\n",
      "Flipped = False\n",
      "--------------------------------------\n",
      "G's Arch. = U-net256\n",
      "D's Arch. = PatchGAN\n",
      "num. of D's layers = 3\n",
      "num. of Input's Channels = 3\n",
      "num. of Output's Channels = 3\n",
      "--------------------------------------\n",
      "Batch Size = 32\n",
      "Normalization = instance\n",
      "G's Dropout = False\n",
      "D's Dropout = True\n",
      "--------------------------------------\n",
      "Loss Mode = vanilla GAN\n",
      "L1's Lambda = 100\n",
      "Beta1 = 0.5\n",
      "Initial Learning-rate = 0.0002\n",
      "Decay Mode = linear\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "wb.config.update({'translate_dirct': translate_dirct, **preproc, **hyper_params})\n",
    "my_utilities.print_config(device, model_load, model_save, model_name, translate_dirct, {**preproc, **hyper_params})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-10T16:17:38.813733Z",
     "end_time": "2023-10-10T16:17:39.657547Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
