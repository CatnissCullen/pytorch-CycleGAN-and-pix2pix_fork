{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bkkaggle/pytorch-CycleGAN-and-pix2pix/blob/master/pix2pix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wNjDKdQy35h"
   },
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# !git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
   ],
   "metadata": {
    "id": "ZY0Bf_6CX7w0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Pt3igws3eiVp",
    "ExecuteTime": {
     "start_time": "2023-10-03T18:20:07.636089Z",
     "end_time": "2023-10-03T18:20:07.667303Z"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1696335103906,
     "user_tz": -480,
     "elapsed": 480,
     "user": {
      "displayName": "Catniss Cullen",
      "userId": "16439932022125892298"
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/My Drive/Essays/PIX2PIX&CycleGAN/pytorch-CycleGAN-and-pix2pix_fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z1EySlOXwwoa",
    "ExecuteTime": {
     "start_time": "2023-10-03T18:21:11.769239Z",
     "end_time": "2023-10-03T18:21:23.270944Z"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1696334081779,
     "user_tz": -480,
     "elapsed": 20205,
     "user": {
      "displayName": "Catniss Cullen",
      "userId": "16439932022125892298"
     }
    },
    "outputId": "803a0b88-452a-4899-ec5a-1097420e9834"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.15.2+cu118)\n",
      "Collecting dominate>=2.4.0 (from -r requirements.txt (line 3))\n",
      "  Downloading dominate-2.8.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting visdom>=0.1.8.8 (from -r requirements.txt (line 4))\n",
      "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.4/1.4 MB\u001B[0m \u001B[31m14.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting wandb (from -r requirements.txt (line 5))\n",
      "  Downloading wandb-0.15.11-py3-none-any.whl (2.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.1/2.1 MB\u001B[0m \u001B[31m32.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->-r requirements.txt (line 1)) (3.27.4.1)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->-r requirements.txt (line 1)) (16.0.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.23.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (9.4.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.11.2)\n",
      "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (6.3.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.16.0)\n",
      "Collecting jsonpatch (from visdom>=0.1.8.8->-r requirements.txt (line 4))\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.6.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (8.1.7)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 5))\n",
      "  Downloading GitPython-3.1.37-py3-none-any.whl (190 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m190.0/190.0 kB\u001B[0m \u001B[31m25.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (5.9.5)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 5))\n",
      "  Downloading sentry_sdk-1.31.0-py2.py3-none-any.whl (224 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m224.8/224.8 kB\u001B[0m \u001B[31m20.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 5))\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (6.0.1)\n",
      "Collecting pathtools (from wandb->-r requirements.txt (line 5))\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting setproctitle (from wandb->-r requirements.txt (line 5))\n",
      "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (67.7.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (3.20.3)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5))\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.7/62.7 kB\u001B[0m \u001B[31m8.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->-r requirements.txt (line 1)) (2.1.3)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch->visdom>=0.1.8.8->-r requirements.txt (line 4))\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5))\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: visdom, pathtools\n",
      "  Building wheel for visdom (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408194 sha256=ea0ba535d6644742823bb736d79607e44a6032693c23ff6527b72c4243db15dd\n",
      "  Stored in directory: /root/.cache/pip/wheels/42/29/49/5bed207bac4578e4d2c0c5fc0226bfd33a7e2953ea56356855\n",
      "  Building wheel for pathtools (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=28bba0675a15644010c990124b4452a14dabc16f69a2eb88a5ab8e24a73e2d19\n",
      "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
      "Successfully built visdom pathtools\n",
      "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, jsonpointer, dominate, docker-pycreds, jsonpatch, gitdb, visdom, GitPython, wandb\n",
      "\u001B[33m  WARNING: The script visdom is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33m  WARNING: The scripts wandb and wb are installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\u001B[33m\n",
      "\u001B[0mSuccessfully installed GitPython-3.1.37 docker-pycreds-0.4.0 dominate-2.8.0 gitdb-4.0.10 jsonpatch-1.33 jsonpointer-2.4 pathtools-0.1.2 sentry-sdk-1.31.0 setproctitle-1.3.2 smmap-5.0.1 visdom-0.2.4 wandb-0.15.11\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8daqlgVhw29P"
   },
   "source": [
    "# Datasets\n",
    "\n",
    "Download one of the official datasets with:\n",
    "\n",
    "-   `bash ./datasets/download_pix2pix_dataset.sh [cityscapes, night2day, edges2handbags, edges2shoes, facades, maps]`\n",
    "\n",
    "Or use your own dataset by creating the appropriate folders and adding in the images. Follow the instructions [here](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/docs/datasets.md#pix2pix-datasets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdUz4116xhpm"
   },
   "source": [
    "# Pretrained models\n",
    "\n",
    "Download one of the official pretrained models with:\n",
    "\n",
    "-   `bash ./scripts/download_pix2pix_model.sh [edges2shoes, sat2map, map2sat, facades_label2photo, and day2night]`\n",
    "\n",
    "Or add your own pretrained model to `./checkpoints/{NAME}_pretrained/latest_net_G.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Specified [facades]\n",
      "WARNING: timestamping does nothing in combination with -O. See the manual\n",
      "for details.\n",
      "\n",
      "--2023-10-03 12:04:09--  http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/facades.tar.gz\n",
      "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.244.190\n",
      "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.244.190|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 30168306 (29M) [application/x-gzip]\n",
      "Saving to: ‘./datasets/facades.tar.gz’\n",
      "\n",
      "./datasets/facades. 100%[===================>]  28.77M  1.59MB/s    in 44s     \n",
      "\n",
      "2023-10-03 12:04:54 (669 KB/s) - ‘./datasets/facades.tar.gz’ saved [30168306/30168306]\n",
      "\n",
      "facades/\n",
      "facades/test/\n",
      "facades/test/27.jpg\n",
      "facades/test/5.jpg\n",
      "facades/test/72.jpg\n",
      "facades/test/1.jpg\n",
      "facades/test/10.jpg\n",
      "facades/test/100.jpg\n",
      "facades/test/101.jpg\n",
      "facades/test/102.jpg\n",
      "facades/test/103.jpg\n",
      "facades/test/104.jpg\n",
      "facades/test/105.jpg\n",
      "facades/test/106.jpg\n",
      "facades/test/11.jpg\n",
      "facades/test/12.jpg\n",
      "facades/test/13.jpg\n",
      "facades/test/14.jpg\n",
      "facades/test/15.jpg\n",
      "facades/test/16.jpg\n",
      "facades/test/17.jpg\n",
      "facades/test/18.jpg\n",
      "facades/test/19.jpg\n",
      "facades/test/2.jpg\n",
      "facades/test/20.jpg\n",
      "facades/test/21.jpg\n",
      "facades/test/22.jpg\n",
      "facades/test/23.jpg\n",
      "facades/test/24.jpg\n",
      "facades/test/25.jpg\n",
      "facades/test/26.jpg\n",
      "facades/test/50.jpg\n",
      "facades/test/51.jpg\n",
      "facades/test/52.jpg\n",
      "facades/test/53.jpg\n",
      "facades/test/54.jpg\n",
      "facades/test/55.jpg\n",
      "facades/test/56.jpg\n",
      "facades/test/57.jpg\n",
      "facades/test/58.jpg\n",
      "facades/test/59.jpg\n",
      "facades/test/6.jpg\n",
      "facades/test/60.jpg\n",
      "facades/test/61.jpg\n",
      "facades/test/62.jpg\n",
      "facades/test/63.jpg\n",
      "facades/test/64.jpg\n",
      "facades/test/65.jpg\n",
      "facades/test/66.jpg\n",
      "facades/test/67.jpg\n",
      "facades/test/68.jpg\n",
      "facades/test/69.jpg\n",
      "facades/test/7.jpg\n",
      "facades/test/70.jpg\n",
      "facades/test/71.jpg\n",
      "facades/test/73.jpg\n",
      "facades/test/74.jpg\n",
      "facades/test/75.jpg\n",
      "facades/test/76.jpg\n",
      "facades/test/77.jpg\n",
      "facades/test/78.jpg\n",
      "facades/test/79.jpg\n",
      "facades/test/8.jpg\n",
      "facades/test/80.jpg\n",
      "facades/test/81.jpg\n",
      "facades/test/82.jpg\n",
      "facades/test/83.jpg\n",
      "facades/test/84.jpg\n",
      "facades/test/85.jpg\n",
      "facades/test/86.jpg\n",
      "facades/test/87.jpg\n",
      "facades/test/88.jpg\n",
      "facades/test/89.jpg\n",
      "facades/test/9.jpg\n",
      "facades/test/90.jpg\n",
      "facades/test/91.jpg\n",
      "facades/test/92.jpg\n",
      "facades/test/93.jpg\n",
      "facades/test/94.jpg\n",
      "facades/test/95.jpg\n",
      "facades/test/96.jpg\n",
      "facades/test/97.jpg\n",
      "facades/test/98.jpg\n",
      "facades/test/99.jpg\n",
      "facades/test/28.jpg\n",
      "facades/test/29.jpg\n",
      "facades/test/3.jpg\n",
      "facades/test/30.jpg\n",
      "facades/test/31.jpg\n",
      "facades/test/32.jpg\n",
      "facades/test/33.jpg\n",
      "facades/test/34.jpg\n",
      "facades/test/35.jpg\n",
      "facades/test/36.jpg\n",
      "facades/test/37.jpg\n",
      "facades/test/38.jpg\n",
      "facades/test/39.jpg\n",
      "facades/test/4.jpg\n",
      "facades/test/40.jpg\n",
      "facades/test/41.jpg\n",
      "facades/test/42.jpg\n",
      "facades/test/43.jpg\n",
      "facades/test/44.jpg\n",
      "facades/test/45.jpg\n",
      "facades/test/46.jpg\n",
      "facades/test/47.jpg\n",
      "facades/test/48.jpg\n",
      "facades/test/49.jpg\n",
      "facades/train/\n",
      "facades/train/1.jpg\n",
      "facades/train/10.jpg\n",
      "facades/train/100.jpg\n",
      "facades/train/101.jpg\n",
      "facades/train/102.jpg\n",
      "facades/train/103.jpg\n",
      "facades/train/104.jpg\n",
      "facades/train/105.jpg\n",
      "facades/train/106.jpg\n",
      "facades/train/107.jpg\n",
      "facades/train/108.jpg\n",
      "facades/train/109.jpg\n",
      "facades/train/11.jpg\n",
      "facades/train/110.jpg\n",
      "facades/train/111.jpg\n",
      "facades/train/112.jpg\n",
      "facades/train/113.jpg\n",
      "facades/train/114.jpg\n",
      "facades/train/115.jpg\n",
      "facades/train/116.jpg\n",
      "facades/train/117.jpg\n",
      "facades/train/118.jpg\n",
      "facades/train/119.jpg\n",
      "facades/train/12.jpg\n",
      "facades/train/120.jpg\n",
      "facades/train/121.jpg\n",
      "facades/train/122.jpg\n",
      "facades/train/123.jpg\n",
      "facades/train/124.jpg\n",
      "facades/train/125.jpg\n",
      "facades/train/126.jpg\n",
      "facades/train/309.jpg\n",
      "facades/train/31.jpg\n",
      "facades/train/310.jpg\n",
      "facades/train/311.jpg\n",
      "facades/train/312.jpg\n",
      "facades/train/313.jpg\n",
      "facades/train/314.jpg\n",
      "facades/train/315.jpg\n",
      "facades/train/316.jpg\n",
      "facades/train/317.jpg\n",
      "facades/train/318.jpg\n",
      "facades/train/319.jpg\n",
      "facades/train/32.jpg\n",
      "facades/train/320.jpg\n",
      "facades/train/321.jpg\n",
      "facades/train/322.jpg\n",
      "facades/train/323.jpg\n",
      "facades/train/324.jpg\n",
      "facades/train/325.jpg\n",
      "facades/train/326.jpg\n",
      "facades/train/327.jpg\n",
      "facades/train/328.jpg\n",
      "facades/train/329.jpg\n",
      "facades/train/390.jpg\n",
      "facades/train/391.jpg\n",
      "facades/train/392.jpg\n",
      "facades/train/393.jpg\n",
      "facades/train/394.jpg\n",
      "facades/train/395.jpg\n",
      "facades/train/396.jpg\n",
      "facades/train/397.jpg\n",
      "facades/train/398.jpg\n",
      "facades/train/399.jpg\n",
      "facades/train/4.jpg\n",
      "facades/train/40.jpg\n",
      "facades/train/400.jpg\n",
      "facades/train/41.jpg\n",
      "facades/train/42.jpg\n",
      "facades/train/43.jpg\n",
      "facades/train/44.jpg\n",
      "facades/train/45.jpg\n",
      "facades/train/46.jpg\n",
      "facades/train/47.jpg\n",
      "facades/train/48.jpg\n",
      "facades/train/49.jpg\n",
      "facades/train/5.jpg\n",
      "facades/train/50.jpg\n",
      "facades/train/51.jpg\n",
      "facades/train/52.jpg\n",
      "facades/train/53.jpg\n",
      "facades/train/54.jpg\n",
      "facades/train/55.jpg\n",
      "facades/train/56.jpg\n",
      "facades/train/57.jpg\n",
      "facades/train/58.jpg\n",
      "facades/train/59.jpg\n",
      "facades/train/6.jpg\n",
      "facades/train/60.jpg\n",
      "facades/train/61.jpg\n",
      "facades/train/222.jpg\n",
      "facades/train/223.jpg\n",
      "facades/train/224.jpg\n",
      "facades/train/225.jpg\n",
      "facades/train/226.jpg\n",
      "facades/train/227.jpg\n",
      "facades/train/228.jpg\n",
      "facades/train/229.jpg\n",
      "facades/train/23.jpg\n",
      "facades/train/230.jpg\n",
      "facades/train/231.jpg\n",
      "facades/train/232.jpg\n",
      "facades/train/233.jpg\n",
      "facades/train/234.jpg\n",
      "facades/train/235.jpg\n",
      "facades/train/236.jpg\n",
      "facades/train/237.jpg\n",
      "facades/train/238.jpg\n",
      "facades/train/239.jpg\n",
      "facades/train/24.jpg\n",
      "facades/train/240.jpg\n",
      "facades/train/241.jpg\n",
      "facades/train/242.jpg\n",
      "facades/train/243.jpg\n",
      "facades/train/244.jpg\n",
      "facades/train/245.jpg\n",
      "facades/train/156.jpg\n",
      "facades/train/157.jpg\n",
      "facades/train/158.jpg\n",
      "facades/train/159.jpg\n",
      "facades/train/16.jpg\n",
      "facades/train/160.jpg\n",
      "facades/train/161.jpg\n",
      "facades/train/162.jpg\n",
      "facades/train/163.jpg\n",
      "facades/train/164.jpg\n",
      "facades/train/165.jpg\n",
      "facades/train/166.jpg\n",
      "facades/train/167.jpg\n",
      "facades/train/168.jpg\n",
      "facades/train/169.jpg\n",
      "facades/train/17.jpg\n",
      "facades/train/170.jpg\n",
      "facades/train/171.jpg\n",
      "facades/train/172.jpg\n",
      "facades/train/173.jpg\n",
      "facades/train/174.jpg\n",
      "facades/train/175.jpg\n",
      "facades/train/176.jpg\n",
      "facades/train/177.jpg\n",
      "facades/train/178.jpg\n",
      "facades/train/179.jpg\n",
      "facades/train/18.jpg\n",
      "facades/train/180.jpg\n",
      "facades/train/181.jpg\n",
      "facades/train/182.jpg\n",
      "facades/train/183.jpg\n",
      "facades/train/184.jpg\n",
      "facades/train/185.jpg\n",
      "facades/train/186.jpg\n",
      "facades/train/187.jpg\n",
      "facades/train/188.jpg\n",
      "facades/train/189.jpg\n",
      "facades/train/19.jpg\n",
      "facades/train/127.jpg\n",
      "facades/train/155.jpg\n",
      "facades/train/190.jpg\n",
      "facades/train/221.jpg\n",
      "facades/train/246.jpg\n",
      "facades/train/27.jpg\n",
      "facades/train/29.jpg\n",
      "facades/train/308.jpg\n",
      "facades/train/33.jpg\n",
      "facades/train/350.jpg\n",
      "facades/train/370.jpg\n",
      "facades/train/39.jpg\n",
      "facades/train/62.jpg\n",
      "facades/train/270.jpg\n",
      "facades/train/271.jpg\n",
      "facades/train/272.jpg\n",
      "facades/train/273.jpg\n",
      "facades/train/274.jpg\n",
      "facades/train/275.jpg\n",
      "facades/train/276.jpg\n",
      "facades/train/277.jpg\n",
      "facades/train/278.jpg\n",
      "facades/train/279.jpg\n",
      "facades/train/28.jpg\n",
      "facades/train/280.jpg\n",
      "facades/train/281.jpg\n",
      "facades/train/282.jpg\n",
      "facades/train/283.jpg\n",
      "facades/train/284.jpg\n",
      "facades/train/285.jpg\n",
      "facades/train/286.jpg\n",
      "facades/train/287.jpg\n",
      "facades/train/288.jpg\n",
      "facades/train/289.jpg\n",
      "facades/train/351.jpg\n",
      "facades/train/352.jpg\n",
      "facades/train/353.jpg\n",
      "facades/train/354.jpg\n",
      "facades/train/355.jpg\n",
      "facades/train/356.jpg\n",
      "facades/train/357.jpg\n",
      "facades/train/358.jpg\n",
      "facades/train/359.jpg\n",
      "facades/train/36.jpg\n",
      "facades/train/360.jpg\n",
      "facades/train/361.jpg\n",
      "facades/train/362.jpg\n",
      "facades/train/363.jpg\n",
      "facades/train/364.jpg\n",
      "facades/train/365.jpg\n",
      "facades/train/366.jpg\n",
      "facades/train/367.jpg\n",
      "facades/train/368.jpg\n",
      "facades/train/369.jpg\n",
      "facades/train/37.jpg\n",
      "facades/train/63.jpg\n",
      "facades/train/64.jpg\n",
      "facades/train/65.jpg\n",
      "facades/train/66.jpg\n",
      "facades/train/67.jpg\n",
      "facades/train/68.jpg\n",
      "facades/train/69.jpg\n",
      "facades/train/7.jpg\n",
      "facades/train/70.jpg\n",
      "facades/train/71.jpg\n",
      "facades/train/72.jpg\n",
      "facades/train/73.jpg\n",
      "facades/train/74.jpg\n",
      "facades/train/75.jpg\n",
      "facades/train/76.jpg\n",
      "facades/train/77.jpg\n",
      "facades/train/78.jpg\n",
      "facades/train/79.jpg\n",
      "facades/train/8.jpg\n",
      "facades/train/80.jpg\n",
      "facades/train/81.jpg\n",
      "facades/train/82.jpg\n",
      "facades/train/83.jpg\n",
      "facades/train/84.jpg\n",
      "facades/train/85.jpg\n",
      "facades/train/86.jpg\n",
      "facades/train/87.jpg\n",
      "facades/train/88.jpg\n",
      "facades/train/89.jpg\n",
      "facades/train/9.jpg\n",
      "facades/train/90.jpg\n",
      "facades/train/91.jpg\n",
      "facades/train/92.jpg\n",
      "facades/train/93.jpg\n",
      "facades/train/94.jpg\n",
      "facades/train/95.jpg\n",
      "facades/train/96.jpg\n",
      "facades/train/97.jpg\n",
      "facades/train/98.jpg\n",
      "facades/train/99.jpg\n",
      "facades/train/128.jpg\n",
      "facades/train/129.jpg\n",
      "facades/train/13.jpg\n",
      "facades/train/130.jpg\n",
      "facades/train/131.jpg\n",
      "facades/train/132.jpg\n",
      "facades/train/133.jpg\n",
      "facades/train/134.jpg\n",
      "facades/train/135.jpg\n",
      "facades/train/136.jpg\n",
      "facades/train/137.jpg\n",
      "facades/train/138.jpg\n",
      "facades/train/139.jpg\n",
      "facades/train/14.jpg\n",
      "facades/train/140.jpg\n",
      "facades/train/141.jpg\n",
      "facades/train/142.jpg\n",
      "facades/train/143.jpg\n",
      "facades/train/144.jpg\n",
      "facades/train/145.jpg\n",
      "facades/train/146.jpg\n",
      "facades/train/147.jpg\n",
      "facades/train/148.jpg\n",
      "facades/train/149.jpg\n",
      "facades/train/15.jpg\n",
      "facades/train/150.jpg\n",
      "facades/train/151.jpg\n",
      "facades/train/152.jpg\n",
      "facades/train/153.jpg\n",
      "facades/train/154.jpg\n",
      "facades/train/191.jpg\n",
      "facades/train/192.jpg\n",
      "facades/train/193.jpg\n",
      "facades/train/194.jpg\n",
      "facades/train/195.jpg\n",
      "facades/train/196.jpg\n",
      "facades/train/197.jpg\n",
      "facades/train/198.jpg\n",
      "facades/train/199.jpg\n",
      "facades/train/2.jpg\n",
      "facades/train/20.jpg\n",
      "facades/train/200.jpg\n",
      "facades/train/201.jpg\n",
      "facades/train/202.jpg\n",
      "facades/train/203.jpg\n",
      "facades/train/204.jpg\n",
      "facades/train/205.jpg\n",
      "facades/train/206.jpg\n",
      "facades/train/207.jpg\n",
      "facades/train/208.jpg\n",
      "facades/train/209.jpg\n",
      "facades/train/21.jpg\n",
      "facades/train/210.jpg\n",
      "facades/train/211.jpg\n",
      "facades/train/212.jpg\n",
      "facades/train/213.jpg\n",
      "facades/train/214.jpg\n",
      "facades/train/215.jpg\n",
      "facades/train/216.jpg\n",
      "facades/train/217.jpg\n",
      "facades/train/218.jpg\n",
      "facades/train/219.jpg\n",
      "facades/train/22.jpg\n",
      "facades/train/220.jpg\n",
      "facades/train/247.jpg\n",
      "facades/train/248.jpg\n",
      "facades/train/249.jpg\n",
      "facades/train/25.jpg\n",
      "facades/train/250.jpg\n",
      "facades/train/251.jpg\n",
      "facades/train/252.jpg\n",
      "facades/train/253.jpg\n",
      "facades/train/254.jpg\n",
      "facades/train/255.jpg\n",
      "facades/train/256.jpg\n",
      "facades/train/257.jpg\n",
      "facades/train/258.jpg\n",
      "facades/train/259.jpg\n",
      "facades/train/26.jpg\n",
      "facades/train/260.jpg\n",
      "facades/train/261.jpg\n",
      "facades/train/262.jpg\n",
      "facades/train/263.jpg\n",
      "facades/train/264.jpg\n",
      "facades/train/265.jpg\n",
      "facades/train/266.jpg\n",
      "facades/train/267.jpg\n",
      "facades/train/268.jpg\n",
      "facades/train/269.jpg\n",
      "facades/train/330.jpg\n",
      "facades/train/331.jpg\n",
      "facades/train/332.jpg\n",
      "facades/train/333.jpg\n",
      "facades/train/334.jpg\n",
      "facades/train/335.jpg\n",
      "facades/train/336.jpg\n",
      "facades/train/337.jpg\n",
      "facades/train/338.jpg\n",
      "facades/train/339.jpg\n",
      "facades/train/34.jpg\n",
      "facades/train/340.jpg\n",
      "facades/train/341.jpg\n",
      "facades/train/342.jpg\n",
      "facades/train/343.jpg\n",
      "facades/train/344.jpg\n",
      "facades/train/345.jpg\n",
      "facades/train/346.jpg\n",
      "facades/train/347.jpg\n",
      "facades/train/348.jpg\n",
      "facades/train/349.jpg\n",
      "facades/train/35.jpg\n",
      "facades/train/290.jpg\n",
      "facades/train/291.jpg\n",
      "facades/train/292.jpg\n",
      "facades/train/293.jpg\n",
      "facades/train/294.jpg\n",
      "facades/train/295.jpg\n",
      "facades/train/296.jpg\n",
      "facades/train/297.jpg\n",
      "facades/train/298.jpg\n",
      "facades/train/299.jpg\n",
      "facades/train/3.jpg\n",
      "facades/train/30.jpg\n",
      "facades/train/300.jpg\n",
      "facades/train/301.jpg\n",
      "facades/train/302.jpg\n",
      "facades/train/303.jpg\n",
      "facades/train/304.jpg\n",
      "facades/train/305.jpg\n",
      "facades/train/306.jpg\n",
      "facades/train/307.jpg\n",
      "facades/train/371.jpg\n",
      "facades/train/372.jpg\n",
      "facades/train/373.jpg\n",
      "facades/train/374.jpg\n",
      "facades/train/375.jpg\n",
      "facades/train/376.jpg\n",
      "facades/train/377.jpg\n",
      "facades/train/378.jpg\n",
      "facades/train/379.jpg\n",
      "facades/train/38.jpg\n",
      "facades/train/380.jpg\n",
      "facades/train/381.jpg\n",
      "facades/train/382.jpg\n",
      "facades/train/383.jpg\n",
      "facades/train/384.jpg\n",
      "facades/train/385.jpg\n",
      "facades/train/386.jpg\n",
      "facades/train/387.jpg\n",
      "facades/train/388.jpg\n",
      "facades/train/389.jpg\n",
      "facades/val/\n",
      "facades/val/30.jpg\n",
      "facades/val/50.jpg\n",
      "facades/val/73.jpg\n",
      "facades/val/1.jpg\n",
      "facades/val/10.jpg\n",
      "facades/val/100.jpg\n",
      "facades/val/11.jpg\n",
      "facades/val/12.jpg\n",
      "facades/val/13.jpg\n",
      "facades/val/14.jpg\n",
      "facades/val/15.jpg\n",
      "facades/val/16.jpg\n",
      "facades/val/17.jpg\n",
      "facades/val/18.jpg\n",
      "facades/val/19.jpg\n",
      "facades/val/2.jpg\n",
      "facades/val/20.jpg\n",
      "facades/val/21.jpg\n",
      "facades/val/22.jpg\n",
      "facades/val/23.jpg\n",
      "facades/val/24.jpg\n",
      "facades/val/25.jpg\n",
      "facades/val/26.jpg\n",
      "facades/val/27.jpg\n",
      "facades/val/28.jpg\n",
      "facades/val/29.jpg\n",
      "facades/val/3.jpg\n",
      "facades/val/51.jpg\n",
      "facades/val/52.jpg\n",
      "facades/val/53.jpg\n",
      "facades/val/54.jpg\n",
      "facades/val/55.jpg\n",
      "facades/val/56.jpg\n",
      "facades/val/57.jpg\n",
      "facades/val/58.jpg\n",
      "facades/val/59.jpg\n",
      "facades/val/6.jpg\n",
      "facades/val/60.jpg\n",
      "facades/val/61.jpg\n",
      "facades/val/62.jpg\n",
      "facades/val/63.jpg\n",
      "facades/val/64.jpg\n",
      "facades/val/65.jpg\n",
      "facades/val/66.jpg\n",
      "facades/val/67.jpg\n",
      "facades/val/68.jpg\n",
      "facades/val/69.jpg\n",
      "facades/val/7.jpg\n",
      "facades/val/70.jpg\n",
      "facades/val/71.jpg\n",
      "facades/val/72.jpg\n",
      "facades/val/74.jpg\n",
      "facades/val/75.jpg\n",
      "facades/val/76.jpg\n",
      "facades/val/77.jpg\n",
      "facades/val/78.jpg\n",
      "facades/val/79.jpg\n",
      "facades/val/8.jpg\n",
      "facades/val/80.jpg\n",
      "facades/val/81.jpg\n",
      "facades/val/82.jpg\n",
      "facades/val/83.jpg\n",
      "facades/val/84.jpg\n",
      "facades/val/85.jpg\n",
      "facades/val/86.jpg\n",
      "facades/val/87.jpg\n",
      "facades/val/88.jpg\n",
      "facades/val/89.jpg\n",
      "facades/val/9.jpg\n",
      "facades/val/90.jpg\n",
      "facades/val/91.jpg\n",
      "facades/val/92.jpg\n",
      "facades/val/93.jpg\n",
      "facades/val/94.jpg\n",
      "facades/val/95.jpg\n",
      "facades/val/96.jpg\n",
      "facades/val/97.jpg\n",
      "facades/val/98.jpg\n",
      "facades/val/99.jpg\n",
      "facades/val/31.jpg\n",
      "facades/val/32.jpg\n",
      "facades/val/33.jpg\n",
      "facades/val/34.jpg\n",
      "facades/val/35.jpg\n",
      "facades/val/36.jpg\n",
      "facades/val/37.jpg\n",
      "facades/val/38.jpg\n",
      "facades/val/39.jpg\n",
      "facades/val/4.jpg\n",
      "facades/val/40.jpg\n",
      "facades/val/41.jpg\n",
      "facades/val/42.jpg\n",
      "facades/val/43.jpg\n",
      "facades/val/44.jpg\n",
      "facades/val/45.jpg\n",
      "facades/val/46.jpg\n",
      "facades/val/47.jpg\n",
      "facades/val/48.jpg\n",
      "facades/val/49.jpg\n",
      "facades/val/5.jpg\n"
     ]
    }
   ],
   "source": [
    "!bash ./datasets/download_pix2pix_dataset.sh facades"
   ],
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-03T18:34:10.348558Z",
     "end_time": "2023-10-03T18:34:16.931879Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-cAiRVz6X7xB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1696334700250,
     "user_tz": -480,
     "elapsed": 49620,
     "user": {
      "displayName": "Catniss Cullen",
      "userId": "16439932022125892298"
     }
    },
    "outputId": "29afb2de-37bb-4cb6-8440-61d2c6c77a18"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GC2DEP4M0OsS",
    "ExecuteTime": {
     "start_time": "2023-10-03T18:34:25.637235Z",
     "end_time": "2023-10-03T18:34:25.940025Z"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1696334731831,
     "user_tz": -480,
     "elapsed": 23930,
     "user": {
      "displayName": "Catniss Cullen",
      "userId": "16439932022125892298"
     }
    },
    "outputId": "3c1b0a61-bb31-468a-dd03-5c7f610aaedc"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Note: available models are edges2shoes, sat2map, map2sat, facades_label2photo, and day2night\n",
      "Specified [facades_label2photo]\n",
      "WARNING: timestamping does nothing in combination with -O. See the manual\n",
      "for details.\n",
      "\n",
      "--2023-10-03 12:05:07--  http://efrosgans.eecs.berkeley.edu/pix2pix/models-pytorch/facades_label2photo.pth\n",
      "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.244.190\n",
      "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.244.190|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 217704720 (208M)\n",
      "Saving to: ‘./checkpoints/facades_label2photo_pretrained/latest_net_G.pth’\n",
      "\n",
      "./checkpoints/facad 100%[===================>] 207.62M  14.9MB/s    in 23s     \n",
      "\n",
      "2023-10-03 12:05:30 (9.07 MB/s) - ‘./checkpoints/facades_label2photo_pretrained/latest_net_G.pth’ saved [217704720/217704720]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bash ./scripts/download_pix2pix_model.sh facades_label2photo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFw1kDQBx3LN"
   },
   "source": [
    "# Training\n",
    "\n",
    "-   `python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA`\n",
    "\n",
    "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. Add `--direction BtoA` if you want to train a model to transfrom from class B to A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0sp7TCT2x9dB",
    "ExecuteTime": {
     "start_time": "2023-10-03T18:34:31.806601Z",
     "end_time": "2023-10-03T18:34:37.581181Z"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1696338227201,
     "user_tz": -480,
     "elapsed": 3061200,
     "user": {
      "displayName": "Catniss Cullen",
      "userId": "16439932022125892298"
     }
    },
    "outputId": "89fd0037-3d36-4dbb-c46d-fefcdb2a6a5f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 64                            \t[default: 1]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/facades            \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: BtoA                          \t[default: AtoB]\n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "                 n_epochs: 100                           \n",
      "           n_epochs_decay: 100                           \n",
      "               n_layers_D: 3                             \n",
      "                     name: facades_pix2pix               \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "The number of training images = 400\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "[Network D] Total number of parameters : 2.769 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "create web directory ./checkpoints/facades_pix2pix/web...\n",
      "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 1 / 200 \t Time Taken: 68 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 2 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 3 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 4, iters: 256, time: 0.056, data: 4.193) G_GAN: 1.059 G_L1: 33.187 D_real: 0.591 D_fake: 0.495 \n",
      "End of epoch 4 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "saving the model at the end of epoch 5, iters 2240\n",
      "End of epoch 5 / 200 \t Time Taken: 17 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 6 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 7 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 8, iters: 64, time: 0.033, data: 0.015) G_GAN: 1.506 G_L1: 31.878 D_real: 0.390 D_fake: 0.929 \n",
      "End of epoch 8 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 9 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "saving the model at the end of epoch 10, iters 4480\n",
      "End of epoch 10 / 200 \t Time Taken: 20 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 11, iters: 320, time: 0.057, data: 0.017) G_GAN: 1.446 G_L1: 29.954 D_real: 0.328 D_fake: 0.271 \n",
      "End of epoch 11 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 12 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 13 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 14 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 15, iters: 128, time: 0.055, data: 0.023) G_GAN: 1.725 G_L1: 32.125 D_real: 0.415 D_fake: 0.313 \n",
      "saving the model at the end of epoch 15, iters 6720\n",
      "End of epoch 15 / 200 \t Time Taken: 20 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 16 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 17 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 18, iters: 384, time: 0.058, data: 0.012) G_GAN: 1.462 G_L1: 30.884 D_real: 0.471 D_fake: 0.157 \n",
      "End of epoch 18 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 19 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "saving the model at the end of epoch 20, iters 8960\n",
      "End of epoch 20 / 200 \t Time Taken: 20 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 21 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 22, iters: 192, time: 0.058, data: 0.022) G_GAN: 1.133 G_L1: 30.043 D_real: 0.911 D_fake: 0.077 \n",
      "End of epoch 22 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 23 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 24 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 25, iters: 448, time: 0.038, data: 0.025) G_GAN: 2.523 G_L1: 31.727 D_real: 0.151 D_fake: 0.398 \n",
      "saving the model at the end of epoch 25, iters 11200\n",
      "End of epoch 25 / 200 \t Time Taken: 18 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 26 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 27 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 28 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 29, iters: 256, time: 0.058, data: 3.420) G_GAN: 1.854 G_L1: 28.361 D_real: 0.303 D_fake: 0.160 \n",
      "End of epoch 29 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "saving the model at the end of epoch 30, iters 13440\n",
      "End of epoch 30 / 200 \t Time Taken: 16 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 31 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 32 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 33, iters: 64, time: 0.033, data: 0.018) G_GAN: 1.019 G_L1: 29.695 D_real: 0.913 D_fake: 0.078 \n",
      "End of epoch 33 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 34 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "saving the model at the end of epoch 35, iters 15680\n",
      "End of epoch 35 / 200 \t Time Taken: 17 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 36, iters: 320, time: 0.059, data: 0.017) G_GAN: 1.302 G_L1: 27.922 D_real: 0.481 D_fake: 0.128 \n",
      "End of epoch 36 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 37 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 38 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 39 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 40, iters: 128, time: 0.058, data: 0.023) G_GAN: 0.753 G_L1: 29.044 D_real: 1.050 D_fake: 0.062 \n",
      "saving the model at the end of epoch 40, iters 17920\n",
      "End of epoch 40 / 200 \t Time Taken: 19 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 41 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 42 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 43, iters: 384, time: 0.059, data: 0.026) G_GAN: 2.527 G_L1: 27.676 D_real: 0.118 D_fake: 0.339 \n",
      "End of epoch 43 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 44 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "saving the model at the end of epoch 45, iters 20160\n",
      "End of epoch 45 / 200 \t Time Taken: 20 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 46 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 47, iters: 192, time: 0.060, data: 0.036) G_GAN: 2.689 G_L1: 29.387 D_real: 0.171 D_fake: 0.484 \n",
      "End of epoch 47 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 48 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 49 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 50, iters: 448, time: 0.040, data: 0.013) G_GAN: 0.615 G_L1: 25.639 D_real: 0.515 D_fake: 0.346 \n",
      "saving the model at the end of epoch 50, iters 22400\n",
      "End of epoch 50 / 200 \t Time Taken: 20 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 51 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 52 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 53 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 54, iters: 256, time: 0.059, data: 2.265) G_GAN: 1.475 G_L1: 28.646 D_real: 0.326 D_fake: 0.260 \n",
      "End of epoch 54 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "saving the model at the end of epoch 55, iters 24640\n",
      "End of epoch 55 / 200 \t Time Taken: 17 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 56 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 57 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 58, iters: 64, time: 0.035, data: 0.016) G_GAN: 1.736 G_L1: 27.263 D_real: 0.246 D_fake: 0.679 \n",
      "End of epoch 58 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 59 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "saving the model at the end of epoch 60, iters 26880\n",
      "End of epoch 60 / 200 \t Time Taken: 20 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 61, iters: 320, time: 0.062, data: 0.016) G_GAN: 2.129 G_L1: 27.352 D_real: 0.219 D_fake: 0.582 \n",
      "End of epoch 61 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 62 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 63 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 64 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 65, iters: 128, time: 0.059, data: 0.029) G_GAN: 2.665 G_L1: 26.240 D_real: 0.722 D_fake: 0.942 \n",
      "saving the model at the end of epoch 65, iters 29120\n",
      "End of epoch 65 / 200 \t Time Taken: 21 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 66 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 67 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 68, iters: 384, time: 0.060, data: 0.032) G_GAN: 1.805 G_L1: 27.148 D_real: 0.312 D_fake: 0.326 \n",
      "End of epoch 68 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 69 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "saving the model at the end of epoch 70, iters 31360\n",
      "End of epoch 70 / 200 \t Time Taken: 19 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 71 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 72, iters: 192, time: 0.060, data: 0.024) G_GAN: 1.475 G_L1: 26.809 D_real: 0.351 D_fake: 0.337 \n",
      "End of epoch 72 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 73 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 74 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 75, iters: 448, time: 0.040, data: 0.018) G_GAN: 1.765 G_L1: 25.947 D_real: 0.441 D_fake: 0.651 \n",
      "saving the model at the end of epoch 75, iters 33600\n",
      "End of epoch 75 / 200 \t Time Taken: 20 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 76 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 77 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 78 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 79, iters: 256, time: 0.060, data: 2.634) G_GAN: 0.896 G_L1: 26.506 D_real: 1.088 D_fake: 0.125 \n",
      "End of epoch 79 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "saving the model at the end of epoch 80, iters 35840\n",
      "End of epoch 80 / 200 \t Time Taken: 19 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 81 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 82 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 83, iters: 64, time: 0.036, data: 0.015) G_GAN: 1.972 G_L1: 25.827 D_real: 0.163 D_fake: 0.610 \n",
      "End of epoch 83 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 84 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "saving the model at the end of epoch 85, iters 38080\n",
      "End of epoch 85 / 200 \t Time Taken: 17 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 86, iters: 320, time: 0.060, data: 0.018) G_GAN: 1.331 G_L1: 25.852 D_real: 0.375 D_fake: 0.442 \n",
      "End of epoch 86 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 87 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 88 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 89 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 90, iters: 128, time: 0.064, data: 0.013) G_GAN: 1.713 G_L1: 26.183 D_real: 0.557 D_fake: 0.161 \n",
      "saving the latest model (epoch 90, total_iters 40000)\n",
      "saving the model at the end of epoch 90, iters 40320\n",
      "End of epoch 90 / 200 \t Time Taken: 20 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 91 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 92 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 93, iters: 384, time: 0.061, data: 0.020) G_GAN: 1.718 G_L1: 24.276 D_real: 0.263 D_fake: 0.594 \n",
      "End of epoch 93 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 94 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "saving the model at the end of epoch 95, iters 42560\n",
      "End of epoch 95 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 96 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 97, iters: 192, time: 0.061, data: 0.015) G_GAN: 0.384 G_L1: 24.864 D_real: 0.695 D_fake: 0.253 \n",
      "End of epoch 97 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 98 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 99 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0001980\n",
      "(epoch: 100, iters: 448, time: 0.043, data: 0.026) G_GAN: 1.698 G_L1: 25.210 D_real: 0.466 D_fake: 0.634 \n",
      "saving the model at the end of epoch 100, iters 44800\n",
      "End of epoch 100 / 200 \t Time Taken: 21 sec\n",
      "learning rate 0.0001980 -> 0.0001960\n",
      "End of epoch 101 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001960 -> 0.0001941\n",
      "End of epoch 102 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001941 -> 0.0001921\n",
      "End of epoch 103 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001921 -> 0.0001901\n",
      "(epoch: 104, iters: 256, time: 0.061, data: 2.373) G_GAN: 1.033 G_L1: 24.126 D_real: 0.534 D_fake: 0.200 \n",
      "End of epoch 104 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001901 -> 0.0001881\n",
      "saving the model at the end of epoch 105, iters 47040\n",
      "End of epoch 105 / 200 \t Time Taken: 17 sec\n",
      "learning rate 0.0001881 -> 0.0001861\n",
      "End of epoch 106 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001861 -> 0.0001842\n",
      "End of epoch 107 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001842 -> 0.0001822\n",
      "(epoch: 108, iters: 64, time: 0.037, data: 0.015) G_GAN: 0.690 G_L1: 24.193 D_real: 1.218 D_fake: 0.120 \n",
      "End of epoch 108 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0001822 -> 0.0001802\n",
      "End of epoch 109 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001802 -> 0.0001782\n",
      "saving the model at the end of epoch 110, iters 49280\n",
      "End of epoch 110 / 200 \t Time Taken: 19 sec\n",
      "learning rate 0.0001782 -> 0.0001762\n",
      "(epoch: 111, iters: 320, time: 0.061, data: 0.018) G_GAN: 0.996 G_L1: 24.784 D_real: 0.959 D_fake: 0.187 \n",
      "End of epoch 111 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001762 -> 0.0001743\n",
      "End of epoch 112 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001743 -> 0.0001723\n",
      "End of epoch 113 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001723 -> 0.0001703\n",
      "End of epoch 114 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001703 -> 0.0001683\n",
      "(epoch: 115, iters: 128, time: 0.063, data: 0.014) G_GAN: 2.041 G_L1: 23.975 D_real: 0.178 D_fake: 0.588 \n",
      "saving the model at the end of epoch 115, iters 51520\n",
      "End of epoch 115 / 200 \t Time Taken: 18 sec\n",
      "learning rate 0.0001683 -> 0.0001663\n",
      "End of epoch 116 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001663 -> 0.0001644\n",
      "End of epoch 117 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001644 -> 0.0001624\n",
      "(epoch: 118, iters: 384, time: 0.062, data: 0.013) G_GAN: 1.643 G_L1: 24.081 D_real: 0.277 D_fake: 0.447 \n",
      "End of epoch 118 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0001624 -> 0.0001604\n",
      "End of epoch 119 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001604 -> 0.0001584\n",
      "saving the model at the end of epoch 120, iters 53760\n",
      "End of epoch 120 / 200 \t Time Taken: 19 sec\n",
      "learning rate 0.0001584 -> 0.0001564\n",
      "End of epoch 121 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001564 -> 0.0001545\n",
      "(epoch: 122, iters: 192, time: 0.061, data: 0.024) G_GAN: 1.114 G_L1: 23.461 D_real: 0.439 D_fake: 0.421 \n",
      "End of epoch 122 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001545 -> 0.0001525\n",
      "End of epoch 123 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001525 -> 0.0001505\n",
      "End of epoch 124 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001505 -> 0.0001485\n",
      "(epoch: 125, iters: 448, time: 0.041, data: 0.014) G_GAN: 1.424 G_L1: 24.625 D_real: 0.518 D_fake: 0.264 \n",
      "saving the model at the end of epoch 125, iters 56000\n",
      "End of epoch 125 / 200 \t Time Taken: 21 sec\n",
      "learning rate 0.0001485 -> 0.0001465\n",
      "End of epoch 126 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001465 -> 0.0001446\n",
      "End of epoch 127 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0001446 -> 0.0001426\n",
      "End of epoch 128 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001426 -> 0.0001406\n",
      "(epoch: 129, iters: 256, time: 0.062, data: 2.405) G_GAN: 1.513 G_L1: 23.228 D_real: 0.341 D_fake: 0.553 \n",
      "End of epoch 129 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0001406 -> 0.0001386\n",
      "saving the model at the end of epoch 130, iters 58240\n",
      "End of epoch 130 / 200 \t Time Taken: 20 sec\n",
      "learning rate 0.0001386 -> 0.0001366\n",
      "End of epoch 131 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0001366 -> 0.0001347\n",
      "End of epoch 132 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001347 -> 0.0001327\n",
      "(epoch: 133, iters: 64, time: 0.036, data: 0.016) G_GAN: 0.612 G_L1: 23.021 D_real: 0.687 D_fake: 0.345 \n",
      "End of epoch 133 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0001327 -> 0.0001307\n",
      "End of epoch 134 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001307 -> 0.0001287\n",
      "saving the model at the end of epoch 135, iters 60480\n",
      "End of epoch 135 / 200 \t Time Taken: 19 sec\n",
      "learning rate 0.0001287 -> 0.0001267\n",
      "(epoch: 136, iters: 320, time: 0.068, data: 0.013) G_GAN: 0.894 G_L1: 23.081 D_real: 0.802 D_fake: 0.292 \n",
      "End of epoch 136 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001267 -> 0.0001248\n",
      "End of epoch 137 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001248 -> 0.0001228\n",
      "End of epoch 138 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001228 -> 0.0001208\n",
      "End of epoch 139 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001208 -> 0.0001188\n",
      "(epoch: 140, iters: 128, time: 0.060, data: 0.026) G_GAN: 1.320 G_L1: 22.892 D_real: 0.384 D_fake: 0.494 \n",
      "saving the model at the end of epoch 140, iters 62720\n",
      "End of epoch 140 / 200 \t Time Taken: 18 sec\n",
      "learning rate 0.0001188 -> 0.0001168\n",
      "End of epoch 141 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001168 -> 0.0001149\n",
      "End of epoch 142 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001149 -> 0.0001129\n",
      "(epoch: 143, iters: 384, time: 0.062, data: 0.015) G_GAN: 1.747 G_L1: 23.569 D_real: 0.140 D_fake: 0.433 \n",
      "End of epoch 143 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0001129 -> 0.0001109\n",
      "End of epoch 144 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001109 -> 0.0001089\n",
      "saving the model at the end of epoch 145, iters 64960\n",
      "End of epoch 145 / 200 \t Time Taken: 16 sec\n",
      "learning rate 0.0001089 -> 0.0001069\n",
      "End of epoch 146 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001069 -> 0.0001050\n",
      "(epoch: 147, iters: 192, time: 0.061, data: 0.023) G_GAN: 0.897 G_L1: 22.816 D_real: 0.591 D_fake: 0.375 \n",
      "End of epoch 147 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0001050 -> 0.0001030\n",
      "End of epoch 148 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0001030 -> 0.0001010\n",
      "End of epoch 149 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0001010 -> 0.0000990\n",
      "(epoch: 150, iters: 448, time: 0.042, data: 0.014) G_GAN: 1.307 G_L1: 22.056 D_real: 0.412 D_fake: 0.325 \n",
      "saving the model at the end of epoch 150, iters 67200\n",
      "End of epoch 150 / 200 \t Time Taken: 16 sec\n",
      "learning rate 0.0000990 -> 0.0000970\n",
      "End of epoch 151 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000970 -> 0.0000950\n",
      "End of epoch 152 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000950 -> 0.0000931\n",
      "End of epoch 153 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000931 -> 0.0000911\n",
      "(epoch: 154, iters: 256, time: 0.063, data: 2.531) G_GAN: 1.194 G_L1: 22.450 D_real: 0.646 D_fake: 0.247 \n",
      "End of epoch 154 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000911 -> 0.0000891\n",
      "saving the model at the end of epoch 155, iters 69440\n",
      "End of epoch 155 / 200 \t Time Taken: 17 sec\n",
      "learning rate 0.0000891 -> 0.0000871\n",
      "End of epoch 156 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0000871 -> 0.0000851\n",
      "End of epoch 157 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000851 -> 0.0000832\n",
      "(epoch: 158, iters: 64, time: 0.037, data: 0.019) G_GAN: 1.625 G_L1: 22.497 D_real: 0.233 D_fake: 0.555 \n",
      "End of epoch 158 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0000832 -> 0.0000812\n",
      "End of epoch 159 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000812 -> 0.0000792\n",
      "saving the model at the end of epoch 160, iters 71680\n",
      "End of epoch 160 / 200 \t Time Taken: 19 sec\n",
      "learning rate 0.0000792 -> 0.0000772\n",
      "(epoch: 161, iters: 320, time: 0.064, data: 0.015) G_GAN: 1.033 G_L1: 21.288 D_real: 0.602 D_fake: 0.290 \n",
      "End of epoch 161 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000772 -> 0.0000752\n",
      "End of epoch 162 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000752 -> 0.0000733\n",
      "End of epoch 163 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0000733 -> 0.0000713\n",
      "End of epoch 164 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000713 -> 0.0000693\n",
      "(epoch: 165, iters: 128, time: 0.064, data: 0.025) G_GAN: 1.279 G_L1: 21.719 D_real: 0.600 D_fake: 0.293 \n",
      "saving the model at the end of epoch 165, iters 73920\n",
      "End of epoch 165 / 200 \t Time Taken: 16 sec\n",
      "learning rate 0.0000693 -> 0.0000673\n",
      "End of epoch 166 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000673 -> 0.0000653\n",
      "End of epoch 167 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0000653 -> 0.0000634\n",
      "(epoch: 168, iters: 384, time: 0.064, data: 0.023) G_GAN: 1.129 G_L1: 22.350 D_real: 0.438 D_fake: 0.459 \n",
      "End of epoch 168 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000634 -> 0.0000614\n",
      "End of epoch 169 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0000614 -> 0.0000594\n",
      "saving the model at the end of epoch 170, iters 76160\n",
      "End of epoch 170 / 200 \t Time Taken: 17 sec\n",
      "learning rate 0.0000594 -> 0.0000574\n",
      "End of epoch 171 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000574 -> 0.0000554\n",
      "(epoch: 172, iters: 192, time: 0.062, data: 0.015) G_GAN: 0.888 G_L1: 21.838 D_real: 0.366 D_fake: 0.673 \n",
      "End of epoch 172 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000554 -> 0.0000535\n",
      "End of epoch 173 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000535 -> 0.0000515\n",
      "End of epoch 174 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000515 -> 0.0000495\n",
      "(epoch: 175, iters: 448, time: 0.045, data: 0.015) G_GAN: 0.942 G_L1: 22.865 D_real: 0.666 D_fake: 0.420 \n",
      "saving the model at the end of epoch 175, iters 78400\n",
      "End of epoch 175 / 200 \t Time Taken: 18 sec\n",
      "learning rate 0.0000495 -> 0.0000475\n",
      "End of epoch 176 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000475 -> 0.0000455\n",
      "End of epoch 177 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000455 -> 0.0000436\n",
      "End of epoch 178 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000436 -> 0.0000416\n",
      "(epoch: 179, iters: 256, time: 0.062, data: 3.035) G_GAN: 1.280 G_L1: 21.568 D_real: 0.732 D_fake: 0.257 \n",
      "saving the latest model (epoch 179, total_iters 80000)\n",
      "End of epoch 179 / 200 \t Time Taken: 16 sec\n",
      "learning rate 0.0000416 -> 0.0000396\n",
      "saving the model at the end of epoch 180, iters 80640\n",
      "End of epoch 180 / 200 \t Time Taken: 21 sec\n",
      "learning rate 0.0000396 -> 0.0000376\n",
      "End of epoch 181 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000376 -> 0.0000356\n",
      "End of epoch 182 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0000356 -> 0.0000337\n",
      "(epoch: 183, iters: 64, time: 0.038, data: 0.017) G_GAN: 1.003 G_L1: 21.349 D_real: 0.296 D_fake: 0.665 \n",
      "End of epoch 183 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000337 -> 0.0000317\n",
      "End of epoch 184 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000317 -> 0.0000297\n",
      "saving the model at the end of epoch 185, iters 82880\n",
      "End of epoch 185 / 200 \t Time Taken: 17 sec\n",
      "learning rate 0.0000297 -> 0.0000277\n",
      "(epoch: 186, iters: 320, time: 0.067, data: 0.018) G_GAN: 1.155 G_L1: 21.389 D_real: 0.494 D_fake: 0.399 \n",
      "End of epoch 186 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000277 -> 0.0000257\n",
      "End of epoch 187 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000257 -> 0.0000238\n",
      "End of epoch 188 / 200 \t Time Taken: 14 sec\n",
      "learning rate 0.0000238 -> 0.0000218\n",
      "End of epoch 189 / 200 \t Time Taken: 15 sec\n",
      "learning rate 0.0000218 -> 0.0000198\n",
      "(epoch: 190, iters: 128, time: 0.065, data: 0.022) G_GAN: 1.027 G_L1: 21.621 D_real: 0.467 D_fake: 0.529 \n",
      "saving the model at the end of epoch 190, iters 85120\n",
      "End of epoch 190 / 200 \t Time Taken: 16 sec\n",
      "learning rate 0.0000198 -> 0.0000178\n",
      "End of epoch 191 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0000178 -> 0.0000158\n",
      "End of epoch 192 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000158 -> 0.0000139\n",
      "(epoch: 193, iters: 384, time: 0.063, data: 0.025) G_GAN: 1.397 G_L1: 20.633 D_real: 0.794 D_fake: 0.259 \n",
      "End of epoch 193 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000139 -> 0.0000119\n",
      "End of epoch 194 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0000119 -> 0.0000099\n",
      "saving the model at the end of epoch 195, iters 87360\n",
      "End of epoch 195 / 200 \t Time Taken: 17 sec\n",
      "learning rate 0.0000099 -> 0.0000079\n",
      "End of epoch 196 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0000079 -> 0.0000059\n",
      "(epoch: 197, iters: 192, time: 0.069, data: 0.013) G_GAN: 1.308 G_L1: 21.881 D_real: 0.431 D_fake: 0.346 \n",
      "End of epoch 197 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000059 -> 0.0000040\n",
      "End of epoch 198 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0000040 -> 0.0000020\n",
      "End of epoch 199 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0000020 -> 0.0000000\n",
      "(epoch: 200, iters: 448, time: 0.043, data: 0.014) G_GAN: 1.235 G_L1: 23.206 D_real: 0.318 D_fake: 0.385 \n",
      "saving the model at the end of epoch 200, iters 89600\n",
      "End of epoch 200 / 200 \t Time Taken: 18 sec\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA --display_id 1 --gpu_ids 0 --batch_size 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UkcaFZiyASl"
   },
   "source": [
    "# Testing\n",
    "\n",
    "-   `python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix`\n",
    "\n",
    "Change the `--dataroot`, `--name`, and `--direction` to be consistent with your trained model's configuration and how you want to transform images.\n",
    "\n",
    "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
    "> Note that we specified --direction BtoA as Facades dataset's A to B direction is photos to labels.\n",
    "\n",
    "> If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use --model test option. See ./scripts/test_single.sh for how to apply a model to Facade label maps (stored in the directory facades/testB).\n",
    "\n",
    "> See a list of currently available models at ./scripts/download_pix2pix_model.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mey7o6j-0368",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1696339013320,
     "user_tz": -480,
     "elapsed": 428,
     "user": {
      "displayName": "Catniss Cullen",
      "userId": "16439932022125892298"
     }
    },
    "outputId": "aa0924df-0b77-4f80-983e-0267fe5dcf21"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " day2night_pretrained\t\t  facades_pix2pix\n",
      "'[edges2shoes,_pretrained'\t  map2sat_pretrained\n",
      " edges2shoes_pretrained\t\t  sat2map_pretrained\n",
      " facades_label2photo_pretrained\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uCsKkEq0yGh0",
    "outputId": "3d83eb24-0fb2-4567-d7c0-e263e6cda16f"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/facades            \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: BtoA                          \t[default: AtoB]\n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: facades_label2photo_pretrained\t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: True                          \t[default: False]\n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/facades_label2photo_pretrained/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "-----------------------------------------------\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: (1) Create a W&B account\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: (2) Use an existing W&B account\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: (3) Don't visualize my results\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Enter your choice: (1)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Invalid choice\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Enter your choice: 2\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: You chose 'Use an existing W&B account'\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: "
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_label2photo_pretrained --use_wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzSKIPUByfiN"
   },
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Mgg8raPyizq"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_fake_B.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0G3oVH9DyqLQ"
   },
   "outputs": [],
   "source": [
    "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_A.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ErK5OC1j1LH4"
   },
   "outputs": [],
   "source": [
    "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_B.png')\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "environment": {
   "name": "tf2-gpu.2-3.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
