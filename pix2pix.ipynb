{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bkkaggle/pytorch-CycleGAN-and-pix2pix/blob/master/pix2pix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wNjDKdQy35h"
   },
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/data/ypq/PIX2PIX_CycleGAN/pytorch-cyclegan-and-pix2pix_fork')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-06T16:13:46.444088Z",
     "end_time": "2023-10-06T16:13:46.477274Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[0m\u001B[01;34mcheckpoints\u001B[0m/    \u001B[01;34mdocs\u001B[0m/            \u001B[01;34mmodels\u001B[0m/        README.md         train.py\r\n",
      "CycleGAN.ipynb  environment.yml  nohup.out      requirements.txt  \u001B[01;34mutil\u001B[0m/\r\n",
      "\u001B[01;34mdata\u001B[0m/           \u001B[01;34mimgs\u001B[0m/            \u001B[01;34moptions\u001B[0m/       \u001B[01;34mscripts\u001B[0m/          \u001B[01;34mwandb\u001B[0m/\r\n",
      "\u001B[01;34mdatasets\u001B[0m/       LICENSE          pix2pix.ipynb  test.py\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-06T16:13:49.791057Z",
     "end_time": "2023-10-06T16:13:49.977208Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z1EySlOXwwoa",
    "ExecuteTime": {
     "start_time": "2023-10-05T15:52:28.775606Z",
     "end_time": "2023-10-05T15:53:19.351349Z"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1696334081779,
     "user_tz": -480,
     "elapsed": 20205,
     "user": {
      "displayName": "Catniss Cullen",
      "userId": "16439932022125892298"
     }
    },
    "outputId": "803a0b88-452a-4899-ec5a-1097420e9834"
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8daqlgVhw29P"
   },
   "source": [
    "# Datasets\n",
    "\n",
    "Download one of the official datasets with:\n",
    "\n",
    "-   `bash ./datasets/download_pix2pix_dataset.sh [cityscapes, night2day, edges2handbags, edges2shoes, facades, maps]`\n",
    "\n",
    "Or use your own dataset by creating the appropriate folders and adding in the images. Follow the instructions [here](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/docs/datasets.md#pix2pix-datasets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdUz4116xhpm"
   },
   "source": [
    "# Pretrained models\n",
    "\n",
    "Download one of the official pretrained models with:\n",
    "\n",
    "-   `bash ./scripts/download_pix2pix_model.sh [edges2shoes, sat2map, map2sat, facades_label2photo, and day2night]`\n",
    "\n",
    "Or add your own pretrained model to `./checkpoints/{NAME}_pretrained/latest_net_G.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# !bash ./datasets/download_pix2pix_dataset.sh facades"
   ],
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-03T18:34:10.348558Z",
     "end_time": "2023-10-03T18:34:16.931879Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-cAiRVz6X7xB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1696334700250,
     "user_tz": -480,
     "elapsed": 49620,
     "user": {
      "displayName": "Catniss Cullen",
      "userId": "16439932022125892298"
     }
    },
    "outputId": "29afb2de-37bb-4cb6-8440-61d2c6c77a18"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GC2DEP4M0OsS",
    "ExecuteTime": {
     "start_time": "2023-10-03T18:34:25.637235Z",
     "end_time": "2023-10-03T18:34:25.940025Z"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1696334731831,
     "user_tz": -480,
     "elapsed": 23930,
     "user": {
      "displayName": "Catniss Cullen",
      "userId": "16439932022125892298"
     }
    },
    "outputId": "3c1b0a61-bb31-468a-dd03-5c7f610aaedc"
   },
   "outputs": [],
   "source": [
    "# !bash ./scripts/download_pix2pix_model.sh facades_label2photo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFw1kDQBx3LN"
   },
   "source": [
    "# Training\n",
    "\n",
    "-   `python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA`\n",
    "\n",
    "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. Add `--direction BtoA` if you want to train a model to transfrom from class B to A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n",
      "Could not connect to Visdom.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/gpu/anaconda3/envs/ypq/lib/python3.8/site-packages/urllib3/connection.py\", line 200, in _new_conn\n",
      "    sock = connection.create_connection(\n",
      "  File \"/home/gpu/anaconda3/envs/ypq/lib/python3.8/site-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
      "    raise err\n",
      "  File \"/home/gpu/anaconda3/envs/ypq/lib/python3.8/site-packages/urllib3/util/connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gpu/anaconda3/envs/ypq/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 790, in urlopen\n",
      "    response = self._make_request(\n",
      "  File \"/home/gpu/anaconda3/envs/ypq/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 496, in _make_request\n",
      "    conn.request(\n",
      "  File \"/home/gpu/anaconda3/envs/ypq/lib/python3.8/site-packages/urllib3/connection.py\", line 388, in request\n",
      "    self.endheaders()\n",
      "  File \"/home/gpu/anaconda3/envs/ypq/lib/python3.8/http/client.py\", line 1251, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/gpu/anaconda3/envs/ypq/lib/python3.8/http/client.py\", line 1011, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/gpu/anaconda3/envs/ypq/lib/python3.8/http/client.py\", line 951, in send\n",
      "    self.connect()\n",
      "  File \"/home/gpu/anaconda3/envs/ypq/lib/python3.8/site-packages/urllib3/connection.py\", line 236, in connect\n",
      "    self.sock = self._new_conn()\n",
      "  File \"/home/gpu/anaconda3/envs/ypq/lib/python3.8/site-packages/urllib3/connection.py\", line 215, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f0d4a85d040>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "urllib3.exceptions.ProxyError: ('Unable to connect to proxy', NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0d4a85d040>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gpu/anaconda3/envs/ypq/lib/python3.8/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/gpu/anaconda3/envs/ypq/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 844, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/gpu/anaconda3/envs/ypq/lib/python3.8/site-packages/urllib3/util/retry.py\", line 515, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=5927): Max retries exceeded with url: http://localhost:8090/env/main (Caused by ProxyError('Unable to connect to proxy', NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0d4a85d040>: Failed to establish a new connection: [Errno 111] Connection refused')))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gpu/anaconda3/envs/ypq/lib/python3.8/site-packages/visdom/__init__.py\", line 756, in _send\n",
      "    return self._handle_post(\n",
      "  File \"/home/gpu/anaconda3/envs/ypq/lib/python3.8/site-packages/visdom/__init__.py\", line 720, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"/home/gpu/anaconda3/envs/ypq/lib/python3.8/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/gpu/anaconda3/envs/ypq/lib/python3.8/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/gpu/anaconda3/envs/ypq/lib/python3.8/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/gpu/anaconda3/envs/ypq/lib/python3.8/site-packages/requests/adapters.py\", line 513, in send\n",
      "    raise ProxyError(e, request=request)\n",
      "requests.exceptions.ProxyError: HTTPConnectionPool(host='127.0.0.1', port=5927): Max retries exceeded with url: http://localhost:8090/env/main (Caused by ProxyError('Unable to connect to proxy', NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0d4a85d040>: Failed to establish a new connection: [Errno 111] Connection refused')))\n"
     ]
    }
   ],
   "source": [
    "from visdom import Visdom\n",
    "\n",
    "# Initialize the Visdom client\n",
    "viz = Visdom(port=8090)\n",
    "\n",
    "# Check the connection\n",
    "if viz.check_connection():\n",
    "    print(\"Connected to Visdom.\")\n",
    "else:\n",
    "    print(\"Could not connect to Visdom.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-06T16:15:22.216801Z",
     "end_time": "2023-10-06T16:15:22.339196Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\r\n",
      "               batch_size: 32                            \t[default: 1]\r\n",
      "                    beta1: 0.5                           \r\n",
      "          checkpoints_dir: ./checkpoints                 \r\n",
      "           continue_train: False                         \r\n",
      "                crop_size: 256                           \r\n",
      "                 dataroot: ./datasets/facades            \t[default: None]\r\n",
      "             dataset_mode: aligned                       \r\n",
      "                direction: BtoA                          \t[default: AtoB]\r\n",
      "              display_env: main                          \r\n",
      "             display_freq: 400                           \r\n",
      "               display_id: 1                             \r\n",
      "            display_ncols: 4                             \r\n",
      "             display_port: 8080                          \r\n",
      "           display_server: http://localhost              \r\n",
      "          display_winsize: 256                           \r\n",
      "                    epoch: latest                        \r\n",
      "              epoch_count: 1                             \r\n",
      "                 gan_mode: vanilla                       \r\n",
      "                  gpu_ids: 0                             \r\n",
      "                init_gain: 0.02                          \r\n",
      "                init_type: normal                        \r\n",
      "                 input_nc: 3                             \r\n",
      "                  isTrain: True                          \t[default: None]\r\n",
      "                lambda_L1: 100.0                         \r\n",
      "                load_iter: 0                             \t[default: 0]\r\n",
      "                load_size: 286                           \r\n",
      "                       lr: 0.0002                        \r\n",
      "           lr_decay_iters: 50                            \r\n",
      "                lr_policy: linear                        \r\n",
      "         max_dataset_size: inf                           \r\n",
      "                    model: pix2pix                       \t[default: cycle_gan]\r\n",
      "                 n_epochs: 100                           \r\n",
      "           n_epochs_decay: 100                           \r\n",
      "               n_layers_D: 3                             \r\n",
      "                     name: facades_pix2pix               \t[default: experiment_name]\r\n",
      "                      ndf: 64                            \r\n",
      "                     netD: basic                         \r\n",
      "                     netG: unet_256                      \r\n",
      "                      ngf: 64                            \r\n",
      "               no_dropout: False                         \r\n",
      "                  no_flip: False                         \r\n",
      "                  no_html: False                         \r\n",
      "                     norm: batch                         \r\n",
      "              num_threads: 4                             \r\n",
      "                output_nc: 3                             \r\n",
      "                    phase: train                         \r\n",
      "                pool_size: 0                             \r\n",
      "               preprocess: resize_and_crop               \r\n",
      "               print_freq: 100                           \r\n",
      "             save_by_iter: False                         \r\n",
      "          save_epoch_freq: 5                             \r\n",
      "         save_latest_freq: 5000                          \r\n",
      "           serial_batches: False                         \r\n",
      "                   suffix:                               \r\n",
      "         update_html_freq: 1000                          \r\n",
      "                use_wandb: False                         \r\n",
      "                  verbose: False                         \r\n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \r\n",
      "----------------- End -------------------\r\n",
      "dataset [AlignedDataset] was created\r\n",
      "The number of training images = 397\r\n",
      "initialize network with normal\r\n",
      "initialize network with normal\r\n",
      "model [Pix2PixModel] was created\r\n",
      "---------- Networks initialized -------------\r\n",
      "[Network G] Total number of parameters : 54.414 M\r\n",
      "[Network D] Total number of parameters : 2.769 M\r\n",
      "-----------------------------------------------\r\n",
      "Setting up a new session...\r\n",
      "create web directory ./checkpoints/facades_pix2pix/web...\r\n",
      "/home/gpu/anaconda3/envs/ypq/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\r\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 1 / 200 \t Time Taken: 7 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 2, iters: 384, time: 0.024, data: 1.674) G_GAN: 1.042 G_L1: 34.576 D_real: 0.535 D_fake: 0.540 \r\n",
      "End of epoch 2 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 3 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 4, iters: 352, time: 0.022, data: 0.016) G_GAN: 1.153 G_L1: 32.438 D_real: 0.797 D_fake: 0.355 \r\n",
      "End of epoch 4 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "saving the model at the end of epoch 5, iters 2080\r\n",
      "End of epoch 5 / 200 \t Time Taken: 6 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 6, iters: 320, time: 0.029, data: 0.014) G_GAN: 1.676 G_L1: 32.333 D_real: 0.415 D_fake: 0.339 \r\n",
      "End of epoch 6 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 7 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 8, iters: 288, time: 0.020, data: 0.013) G_GAN: 2.029 G_L1: 32.534 D_real: 0.516 D_fake: 0.159 \r\n",
      "End of epoch 8 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 9 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 10, iters: 256, time: 0.024, data: 0.013) G_GAN: 1.705 G_L1: 31.416 D_real: 0.214 D_fake: 0.154 \r\n",
      "saving the model at the end of epoch 10, iters 4160\r\n",
      "End of epoch 10 / 200 \t Time Taken: 6 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 11 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 12, iters: 224, time: 0.028, data: 0.016) G_GAN: 2.061 G_L1: 32.361 D_real: 0.356 D_fake: 0.240 \r\n",
      "End of epoch 12 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 13 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 14, iters: 192, time: 0.025, data: 0.013) G_GAN: 2.073 G_L1: 30.705 D_real: 0.282 D_fake: 0.569 \r\n",
      "End of epoch 14 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "saving the model at the end of epoch 15, iters 6240\r\n",
      "End of epoch 15 / 200 \t Time Taken: 6 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 16, iters: 160, time: 0.040, data: 0.011) G_GAN: 2.775 G_L1: 33.357 D_real: 0.115 D_fake: 0.212 \r\n",
      "End of epoch 16 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 17 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 18, iters: 128, time: 0.020, data: 0.007) G_GAN: 2.918 G_L1: 33.495 D_real: 0.103 D_fake: 0.636 \r\n",
      "End of epoch 18 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 19 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 20, iters: 96, time: 0.030, data: 0.014) G_GAN: 2.132 G_L1: 31.444 D_real: 0.337 D_fake: 0.673 \r\n",
      "saving the model at the end of epoch 20, iters 8320\r\n",
      "End of epoch 20 / 200 \t Time Taken: 7 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 21 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 22, iters: 64, time: 0.025, data: 0.013) G_GAN: 3.033 G_L1: 31.835 D_real: 0.090 D_fake: 0.561 \r\n",
      "End of epoch 22 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 23 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 24, iters: 32, time: 0.026, data: 0.016) G_GAN: 3.125 G_L1: 33.531 D_real: 0.105 D_fake: 0.348 \r\n",
      "End of epoch 24 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 25, iters: 416, time: 0.022, data: 0.014) G_GAN: 2.860 G_L1: 34.398 D_real: 0.073 D_fake: 0.215 \r\n",
      "saving the model at the end of epoch 25, iters 10400\r\n",
      "End of epoch 25 / 200 \t Time Taken: 7 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 26 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 27, iters: 384, time: 0.031, data: 1.677) G_GAN: 1.594 G_L1: 31.388 D_real: 0.442 D_fake: 0.151 \r\n",
      "End of epoch 27 / 200 \t Time Taken: 5 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 28 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 29, iters: 352, time: 0.024, data: 0.014) G_GAN: 2.375 G_L1: 29.452 D_real: 0.301 D_fake: 0.468 \r\n",
      "End of epoch 29 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "saving the model at the end of epoch 30, iters 12480\r\n",
      "End of epoch 30 / 200 \t Time Taken: 6 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 31, iters: 320, time: 0.022, data: 0.017) G_GAN: 1.998 G_L1: 30.878 D_real: 0.252 D_fake: 0.185 \r\n",
      "End of epoch 31 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 32 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 33, iters: 288, time: 0.021, data: 0.013) G_GAN: 2.312 G_L1: 30.239 D_real: 0.706 D_fake: 0.042 \r\n",
      "End of epoch 33 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 34 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 35, iters: 256, time: 0.026, data: 0.014) G_GAN: 2.367 G_L1: 31.141 D_real: 0.242 D_fake: 0.453 \r\n",
      "saving the model at the end of epoch 35, iters 14560\r\n",
      "End of epoch 35 / 200 \t Time Taken: 7 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 36 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 37, iters: 224, time: 0.021, data: 0.014) G_GAN: 2.921 G_L1: 29.207 D_real: 0.133 D_fake: 0.777 \r\n",
      "End of epoch 37 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 38 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 39, iters: 192, time: 0.023, data: 0.016) G_GAN: 2.446 G_L1: 28.777 D_real: 0.093 D_fake: 0.630 \r\n",
      "End of epoch 39 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "saving the model at the end of epoch 40, iters 16640\r\n",
      "End of epoch 40 / 200 \t Time Taken: 6 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 41, iters: 160, time: 0.025, data: 0.011) G_GAN: 1.776 G_L1: 29.306 D_real: 0.252 D_fake: 0.452 \r\n",
      "End of epoch 41 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 42 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 43, iters: 128, time: 0.028, data: 0.011) G_GAN: 1.546 G_L1: 29.496 D_real: 0.588 D_fake: 0.125 \r\n",
      "End of epoch 43 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 44 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 45, iters: 96, time: 0.027, data: 0.014) G_GAN: 0.824 G_L1: 29.364 D_real: 1.026 D_fake: 0.122 \r\n",
      "saving the model at the end of epoch 45, iters 18720\r\n",
      "End of epoch 45 / 200 \t Time Taken: 7 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 46 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 47, iters: 64, time: 0.022, data: 0.013) G_GAN: 1.811 G_L1: 28.986 D_real: 0.396 D_fake: 0.242 \r\n",
      "End of epoch 47 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 48 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 49, iters: 32, time: 0.019, data: 0.013) G_GAN: 0.867 G_L1: 29.093 D_real: 0.616 D_fake: 0.206 \r\n",
      "saving the latest model (epoch 49, total_iters 20000)\r\n",
      "End of epoch 49 / 200 \t Time Taken: 5 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 50, iters: 416, time: 0.022, data: 0.007) G_GAN: 2.849 G_L1: 28.988 D_real: 0.050 D_fake: 0.717 \r\n",
      "saving the model at the end of epoch 50, iters 20800\r\n",
      "End of epoch 50 / 200 \t Time Taken: 7 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 51 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 52, iters: 384, time: 0.030, data: 1.688) G_GAN: 0.855 G_L1: 29.163 D_real: 0.618 D_fake: 0.141 \r\n",
      "End of epoch 52 / 200 \t Time Taken: 5 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 53 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 54, iters: 352, time: 0.022, data: 0.016) G_GAN: 1.239 G_L1: 27.314 D_real: 0.253 D_fake: 0.202 \r\n",
      "End of epoch 54 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "saving the model at the end of epoch 55, iters 22880\r\n",
      "End of epoch 55 / 200 \t Time Taken: 7 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 56, iters: 320, time: 0.026, data: 0.012) G_GAN: 1.935 G_L1: 26.828 D_real: 0.635 D_fake: 0.414 \r\n",
      "End of epoch 56 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 57 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 58, iters: 288, time: 0.018, data: 0.014) G_GAN: 2.728 G_L1: 27.121 D_real: 0.095 D_fake: 1.018 \r\n",
      "End of epoch 58 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 59 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 60, iters: 256, time: 0.024, data: 0.016) G_GAN: 2.015 G_L1: 28.268 D_real: 0.142 D_fake: 0.404 \r\n",
      "saving the model at the end of epoch 60, iters 24960\r\n",
      "End of epoch 60 / 200 \t Time Taken: 7 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 61 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 62, iters: 224, time: 0.021, data: 0.014) G_GAN: 2.409 G_L1: 27.423 D_real: 0.088 D_fake: 1.088 \r\n",
      "End of epoch 62 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 63 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 64, iters: 192, time: 0.025, data: 0.012) G_GAN: 1.174 G_L1: 27.364 D_real: 0.668 D_fake: 0.267 \r\n",
      "End of epoch 64 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "saving the model at the end of epoch 65, iters 27040\r\n",
      "End of epoch 65 / 200 \t Time Taken: 6 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 66, iters: 160, time: 0.021, data: 0.015) G_GAN: 2.448 G_L1: 26.699 D_real: 0.105 D_fake: 0.912 \r\n",
      "End of epoch 66 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 67 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 68, iters: 128, time: 0.030, data: 0.015) G_GAN: 2.093 G_L1: 26.325 D_real: 0.116 D_fake: 1.072 \r\n",
      "End of epoch 68 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 69 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 70, iters: 96, time: 0.022, data: 0.017) G_GAN: 2.298 G_L1: 25.508 D_real: 0.179 D_fake: 0.432 \r\n",
      "saving the model at the end of epoch 70, iters 29120\r\n",
      "End of epoch 70 / 200 \t Time Taken: 6 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 71 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 72, iters: 64, time: 0.043, data: 0.012) G_GAN: 2.892 G_L1: 25.594 D_real: 0.038 D_fake: 1.023 \r\n",
      "End of epoch 72 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 73 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 74, iters: 32, time: 0.023, data: 0.013) G_GAN: 0.864 G_L1: 28.195 D_real: 1.676 D_fake: 0.105 \r\n",
      "End of epoch 74 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 75, iters: 416, time: 0.026, data: 0.012) G_GAN: 2.792 G_L1: 27.939 D_real: 0.065 D_fake: 0.824 \r\n",
      "saving the model at the end of epoch 75, iters 31200\r\n",
      "End of epoch 75 / 200 \t Time Taken: 7 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 76 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 77, iters: 384, time: 0.025, data: 1.744) G_GAN: 1.028 G_L1: 24.405 D_real: 0.546 D_fake: 0.291 \r\n",
      "End of epoch 77 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 78 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 79, iters: 352, time: 0.022, data: 0.009) G_GAN: 1.829 G_L1: 25.168 D_real: 0.293 D_fake: 0.375 \r\n",
      "End of epoch 79 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "saving the model at the end of epoch 80, iters 33280\r\n",
      "End of epoch 80 / 200 \t Time Taken: 6 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 81, iters: 320, time: 0.028, data: 0.013) G_GAN: 1.998 G_L1: 25.713 D_real: 0.139 D_fake: 0.626 \r\n",
      "End of epoch 81 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 82 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 83, iters: 288, time: 0.034, data: 0.013) G_GAN: 1.579 G_L1: 26.189 D_real: 0.337 D_fake: 0.406 \r\n",
      "End of epoch 83 / 200 \t Time Taken: 5 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 84 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 85, iters: 256, time: 0.028, data: 0.017) G_GAN: 1.285 G_L1: 25.681 D_real: 0.372 D_fake: 0.358 \r\n",
      "saving the model at the end of epoch 85, iters 35360\r\n",
      "End of epoch 85 / 200 \t Time Taken: 7 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 86 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 87, iters: 224, time: 0.025, data: 0.017) G_GAN: 1.353 G_L1: 24.135 D_real: 0.377 D_fake: 0.341 \r\n",
      "End of epoch 87 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 88 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 89, iters: 192, time: 0.025, data: 0.014) G_GAN: 1.605 G_L1: 23.899 D_real: 0.321 D_fake: 0.253 \r\n",
      "End of epoch 89 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "saving the model at the end of epoch 90, iters 37440\r\n",
      "End of epoch 90 / 200 \t Time Taken: 7 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 91, iters: 160, time: 0.021, data: 0.013) G_GAN: 1.527 G_L1: 25.322 D_real: 0.556 D_fake: 0.324 \r\n",
      "End of epoch 91 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 92 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 93, iters: 128, time: 0.025, data: 0.013) G_GAN: 1.402 G_L1: 25.972 D_real: 0.183 D_fake: 0.347 \r\n",
      "End of epoch 93 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 94 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 95, iters: 96, time: 0.024, data: 0.019) G_GAN: 1.181 G_L1: 24.810 D_real: 0.430 D_fake: 0.622 \r\n",
      "saving the model at the end of epoch 95, iters 39520\r\n",
      "End of epoch 95 / 200 \t Time Taken: 7 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 96 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 97, iters: 64, time: 0.021, data: 0.013) G_GAN: 1.789 G_L1: 25.464 D_real: 0.338 D_fake: 0.258 \r\n",
      "saving the latest model (epoch 97, total_iters 40000)\r\n",
      "End of epoch 97 / 200 \t Time Taken: 5 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "End of epoch 98 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0002000 -> 0.0002000\r\n",
      "(epoch: 99, iters: 32, time: 0.022, data: 0.008) G_GAN: 1.176 G_L1: 25.425 D_real: 1.545 D_fake: 0.086 \r\n",
      "End of epoch 99 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0002000 -> 0.0001980\r\n",
      "(epoch: 100, iters: 416, time: 0.023, data: 0.015) G_GAN: 0.516 G_L1: 23.187 D_real: 1.103 D_fake: 0.223 \r\n",
      "saving the model at the end of epoch 100, iters 41600\r\n",
      "End of epoch 100 / 200 \t Time Taken: 7 sec\r\n",
      "learning rate 0.0001980 -> 0.0001960\r\n",
      "End of epoch 101 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0001960 -> 0.0001941\r\n",
      "(epoch: 102, iters: 384, time: 0.024, data: 1.591) G_GAN: 0.737 G_L1: 23.180 D_real: 0.899 D_fake: 0.300 \r\n",
      "End of epoch 102 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001941 -> 0.0001921\r\n",
      "End of epoch 103 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0001921 -> 0.0001901\r\n",
      "(epoch: 104, iters: 352, time: 0.023, data: 0.014) G_GAN: 0.912 G_L1: 24.287 D_real: 0.530 D_fake: 0.491 \r\n",
      "End of epoch 104 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001901 -> 0.0001881\r\n",
      "saving the model at the end of epoch 105, iters 43680\r\n",
      "End of epoch 105 / 200 \t Time Taken: 6 sec\r\n",
      "learning rate 0.0001881 -> 0.0001861\r\n",
      "(epoch: 106, iters: 320, time: 0.028, data: 0.014) G_GAN: 1.615 G_L1: 24.459 D_real: 0.482 D_fake: 0.231 \r\n",
      "End of epoch 106 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001861 -> 0.0001842\r\n",
      "End of epoch 107 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0001842 -> 0.0001822\r\n",
      "(epoch: 108, iters: 288, time: 0.025, data: 0.014) G_GAN: 0.716 G_L1: 24.668 D_real: 0.571 D_fake: 0.283 \r\n",
      "End of epoch 108 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001822 -> 0.0001802\r\n",
      "End of epoch 109 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0001802 -> 0.0001782\r\n",
      "(epoch: 110, iters: 256, time: 0.027, data: 0.014) G_GAN: 1.224 G_L1: 23.057 D_real: 0.928 D_fake: 0.144 \r\n",
      "saving the model at the end of epoch 110, iters 45760\r\n",
      "End of epoch 110 / 200 \t Time Taken: 7 sec\r\n",
      "learning rate 0.0001782 -> 0.0001762\r\n",
      "End of epoch 111 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0001762 -> 0.0001743\r\n",
      "(epoch: 112, iters: 224, time: 0.024, data: 0.017) G_GAN: 2.142 G_L1: 24.276 D_real: 0.162 D_fake: 0.559 \r\n",
      "End of epoch 112 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001743 -> 0.0001723\r\n",
      "End of epoch 113 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0001723 -> 0.0001703\r\n",
      "(epoch: 114, iters: 192, time: 0.026, data: 0.013) G_GAN: 1.461 G_L1: 23.369 D_real: 0.497 D_fake: 0.217 \r\n",
      "End of epoch 114 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001703 -> 0.0001683\r\n",
      "saving the model at the end of epoch 115, iters 47840\r\n",
      "End of epoch 115 / 200 \t Time Taken: 6 sec\r\n",
      "learning rate 0.0001683 -> 0.0001663\r\n",
      "(epoch: 116, iters: 160, time: 0.032, data: 0.011) G_GAN: 0.648 G_L1: 23.480 D_real: 0.810 D_fake: 0.364 \r\n",
      "End of epoch 116 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001663 -> 0.0001644\r\n",
      "End of epoch 117 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0001644 -> 0.0001624\r\n",
      "(epoch: 118, iters: 128, time: 0.029, data: 0.017) G_GAN: 1.719 G_L1: 23.201 D_real: 0.174 D_fake: 1.077 \r\n",
      "End of epoch 118 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001624 -> 0.0001604\r\n",
      "End of epoch 119 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0001604 -> 0.0001584\r\n",
      "(epoch: 120, iters: 96, time: 0.029, data: 0.015) G_GAN: 0.943 G_L1: 23.553 D_real: 0.586 D_fake: 0.306 \r\n",
      "saving the model at the end of epoch 120, iters 49920\r\n",
      "End of epoch 120 / 200 \t Time Taken: 7 sec\r\n",
      "learning rate 0.0001584 -> 0.0001564\r\n",
      "End of epoch 121 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0001564 -> 0.0001545\r\n",
      "(epoch: 122, iters: 64, time: 0.025, data: 0.014) G_GAN: 1.158 G_L1: 22.966 D_real: 0.405 D_fake: 0.424 \r\n",
      "End of epoch 122 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001545 -> 0.0001525\r\n",
      "End of epoch 123 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0001525 -> 0.0001505\r\n",
      "(epoch: 124, iters: 32, time: 0.022, data: 0.013) G_GAN: 1.010 G_L1: 22.896 D_real: 1.071 D_fake: 0.142 \r\n",
      "End of epoch 124 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001505 -> 0.0001485\r\n",
      "(epoch: 125, iters: 416, time: 0.026, data: 0.015) G_GAN: 0.598 G_L1: 22.989 D_real: 1.312 D_fake: 0.171 \r\n",
      "saving the model at the end of epoch 125, iters 52000\r\n",
      "End of epoch 125 / 200 \t Time Taken: 7 sec\r\n",
      "learning rate 0.0001485 -> 0.0001465\r\n",
      "End of epoch 126 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0001465 -> 0.0001446\r\n",
      "(epoch: 127, iters: 384, time: 0.025, data: 1.660) G_GAN: 1.411 G_L1: 21.976 D_real: 0.265 D_fake: 0.551 \r\n",
      "End of epoch 127 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001446 -> 0.0001426\r\n",
      "End of epoch 128 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0001426 -> 0.0001406\r\n",
      "(epoch: 129, iters: 352, time: 0.026, data: 0.016) G_GAN: 1.168 G_L1: 23.302 D_real: 0.686 D_fake: 0.295 \r\n",
      "End of epoch 129 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001406 -> 0.0001386\r\n",
      "saving the model at the end of epoch 130, iters 54080\r\n",
      "End of epoch 130 / 200 \t Time Taken: 6 sec\r\n",
      "learning rate 0.0001386 -> 0.0001366\r\n",
      "(epoch: 131, iters: 320, time: 0.029, data: 0.013) G_GAN: 1.410 G_L1: 22.478 D_real: 0.248 D_fake: 0.686 \r\n",
      "End of epoch 131 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001366 -> 0.0001347\r\n",
      "End of epoch 132 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0001347 -> 0.0001327\r\n",
      "(epoch: 133, iters: 288, time: 0.028, data: 0.014) G_GAN: 1.590 G_L1: 22.252 D_real: 0.285 D_fake: 0.548 \r\n",
      "End of epoch 133 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001327 -> 0.0001307\r\n",
      "End of epoch 134 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001307 -> 0.0001287\r\n",
      "(epoch: 135, iters: 256, time: 0.027, data: 0.014) G_GAN: 1.149 G_L1: 22.466 D_real: 0.515 D_fake: 0.272 \r\n",
      "saving the model at the end of epoch 135, iters 56160\r\n",
      "End of epoch 135 / 200 \t Time Taken: 7 sec\r\n",
      "learning rate 0.0001287 -> 0.0001267\r\n",
      "End of epoch 136 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0001267 -> 0.0001248\r\n",
      "(epoch: 137, iters: 224, time: 0.022, data: 0.018) G_GAN: 1.011 G_L1: 22.438 D_real: 0.613 D_fake: 0.269 \r\n",
      "End of epoch 137 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001248 -> 0.0001228\r\n",
      "End of epoch 138 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001228 -> 0.0001208\r\n",
      "(epoch: 139, iters: 192, time: 0.024, data: 0.017) G_GAN: 1.763 G_L1: 22.450 D_real: 0.212 D_fake: 0.439 \r\n",
      "End of epoch 139 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001208 -> 0.0001188\r\n",
      "saving the model at the end of epoch 140, iters 58240\r\n",
      "End of epoch 140 / 200 \t Time Taken: 6 sec\r\n",
      "learning rate 0.0001188 -> 0.0001168\r\n",
      "(epoch: 141, iters: 160, time: 0.025, data: 0.013) G_GAN: 1.239 G_L1: 23.064 D_real: 0.347 D_fake: 0.442 \r\n",
      "End of epoch 141 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001168 -> 0.0001149\r\n",
      "End of epoch 142 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0001149 -> 0.0001129\r\n",
      "(epoch: 143, iters: 128, time: 0.027, data: 0.011) G_GAN: 1.630 G_L1: 22.034 D_real: 0.159 D_fake: 0.861 \r\n",
      "End of epoch 143 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001129 -> 0.0001109\r\n",
      "End of epoch 144 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001109 -> 0.0001089\r\n",
      "(epoch: 145, iters: 96, time: 0.024, data: 0.032) G_GAN: 1.726 G_L1: 22.358 D_real: 0.373 D_fake: 0.334 \r\n",
      "saving the latest model (epoch 145, total_iters 60000)\r\n",
      "saving the model at the end of epoch 145, iters 60320\r\n",
      "End of epoch 145 / 200 \t Time Taken: 8 sec\r\n",
      "learning rate 0.0001089 -> 0.0001069\r\n",
      "End of epoch 146 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001069 -> 0.0001050\r\n",
      "(epoch: 147, iters: 64, time: 0.024, data: 0.007) G_GAN: 0.996 G_L1: 21.720 D_real: 0.750 D_fake: 0.370 \r\n",
      "End of epoch 147 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001050 -> 0.0001030\r\n",
      "End of epoch 148 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0001030 -> 0.0001010\r\n",
      "(epoch: 149, iters: 32, time: 0.025, data: 0.016) G_GAN: 1.322 G_L1: 22.662 D_real: 0.577 D_fake: 0.224 \r\n",
      "End of epoch 149 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0001010 -> 0.0000990\r\n",
      "(epoch: 150, iters: 416, time: 0.026, data: 0.014) G_GAN: 1.579 G_L1: 22.377 D_real: 0.136 D_fake: 0.798 \r\n",
      "saving the model at the end of epoch 150, iters 62400\r\n",
      "End of epoch 150 / 200 \t Time Taken: 7 sec\r\n",
      "learning rate 0.0000990 -> 0.0000970\r\n",
      "End of epoch 151 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0000970 -> 0.0000950\r\n",
      "(epoch: 152, iters: 384, time: 0.029, data: 1.730) G_GAN: 1.239 G_L1: 21.563 D_real: 0.247 D_fake: 0.843 \r\n",
      "End of epoch 152 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0000950 -> 0.0000931\r\n",
      "End of epoch 153 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0000931 -> 0.0000911\r\n",
      "(epoch: 154, iters: 352, time: 0.027, data: 0.016) G_GAN: 1.007 G_L1: 21.879 D_real: 0.455 D_fake: 0.391 \r\n",
      "End of epoch 154 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0000911 -> 0.0000891\r\n",
      "saving the model at the end of epoch 155, iters 64480\r\n",
      "End of epoch 155 / 200 \t Time Taken: 6 sec\r\n",
      "learning rate 0.0000891 -> 0.0000871\r\n",
      "(epoch: 156, iters: 320, time: 0.027, data: 0.012) G_GAN: 1.010 G_L1: 22.217 D_real: 0.850 D_fake: 0.191 \r\n",
      "End of epoch 156 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0000871 -> 0.0000851\r\n",
      "End of epoch 157 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0000851 -> 0.0000832\r\n",
      "(epoch: 158, iters: 288, time: 0.027, data: 0.009) G_GAN: 0.651 G_L1: 21.846 D_real: 1.065 D_fake: 0.406 \r\n",
      "End of epoch 158 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0000832 -> 0.0000812\r\n",
      "End of epoch 159 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0000812 -> 0.0000792\r\n",
      "(epoch: 160, iters: 256, time: 0.030, data: 0.014) G_GAN: 1.591 G_L1: 22.184 D_real: 0.326 D_fake: 0.352 \r\n",
      "saving the model at the end of epoch 160, iters 66560\r\n",
      "End of epoch 160 / 200 \t Time Taken: 7 sec\r\n",
      "learning rate 0.0000792 -> 0.0000772\r\n",
      "End of epoch 161 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0000772 -> 0.0000752\r\n",
      "(epoch: 162, iters: 224, time: 0.033, data: 0.014) G_GAN: 1.156 G_L1: 21.579 D_real: 0.486 D_fake: 0.346 \r\n",
      "End of epoch 162 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0000752 -> 0.0000733\r\n",
      "End of epoch 163 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0000733 -> 0.0000713\r\n",
      "(epoch: 164, iters: 192, time: 0.026, data: 0.013) G_GAN: 1.219 G_L1: 20.628 D_real: 0.592 D_fake: 0.311 \r\n",
      "End of epoch 164 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0000713 -> 0.0000693\r\n",
      "saving the model at the end of epoch 165, iters 68640\r\n",
      "End of epoch 165 / 200 \t Time Taken: 6 sec\r\n",
      "learning rate 0.0000693 -> 0.0000673\r\n",
      "(epoch: 166, iters: 160, time: 0.023, data: 0.013) G_GAN: 1.173 G_L1: 21.312 D_real: 0.360 D_fake: 0.388 \r\n",
      "End of epoch 166 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0000673 -> 0.0000653\r\n",
      "End of epoch 167 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0000653 -> 0.0000634\r\n",
      "(epoch: 168, iters: 128, time: 0.026, data: 0.012) G_GAN: 1.310 G_L1: 21.551 D_real: 0.338 D_fake: 0.475 \r\n",
      "End of epoch 168 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0000634 -> 0.0000614\r\n",
      "End of epoch 169 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0000614 -> 0.0000594\r\n",
      "(epoch: 170, iters: 96, time: 0.027, data: 0.032) G_GAN: 1.113 G_L1: 22.244 D_real: 0.449 D_fake: 0.447 \r\n",
      "saving the model at the end of epoch 170, iters 70720\r\n",
      "End of epoch 170 / 200 \t Time Taken: 6 sec\r\n",
      "learning rate 0.0000594 -> 0.0000574\r\n",
      "End of epoch 171 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0000574 -> 0.0000554\r\n",
      "(epoch: 172, iters: 64, time: 0.028, data: 0.014) G_GAN: 1.627 G_L1: 22.042 D_real: 0.079 D_fake: 0.594 \r\n",
      "End of epoch 172 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0000554 -> 0.0000535\r\n",
      "End of epoch 173 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0000535 -> 0.0000515\r\n",
      "(epoch: 174, iters: 32, time: 0.026, data: 0.014) G_GAN: 1.018 G_L1: 20.752 D_real: 0.415 D_fake: 0.420 \r\n",
      "End of epoch 174 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0000515 -> 0.0000495\r\n",
      "(epoch: 175, iters: 416, time: 0.028, data: 0.014) G_GAN: 1.261 G_L1: 22.755 D_real: 0.408 D_fake: 0.530 \r\n",
      "saving the model at the end of epoch 175, iters 72800\r\n",
      "End of epoch 175 / 200 \t Time Taken: 7 sec\r\n",
      "learning rate 0.0000495 -> 0.0000475\r\n",
      "End of epoch 176 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0000475 -> 0.0000455\r\n",
      "(epoch: 177, iters: 384, time: 0.031, data: 1.774) G_GAN: 1.411 G_L1: 21.582 D_real: 0.352 D_fake: 0.385 \r\n",
      "End of epoch 177 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0000455 -> 0.0000436\r\n",
      "End of epoch 178 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0000436 -> 0.0000416\r\n",
      "(epoch: 179, iters: 352, time: 0.030, data: 0.015) G_GAN: 1.234 G_L1: 21.356 D_real: 0.305 D_fake: 0.493 \r\n",
      "End of epoch 179 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0000416 -> 0.0000396\r\n",
      "saving the model at the end of epoch 180, iters 74880\r\n",
      "End of epoch 180 / 200 \t Time Taken: 6 sec\r\n",
      "learning rate 0.0000396 -> 0.0000376\r\n",
      "(epoch: 181, iters: 320, time: 0.028, data: 0.013) G_GAN: 1.410 G_L1: 21.134 D_real: 0.324 D_fake: 0.364 \r\n",
      "End of epoch 181 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0000376 -> 0.0000356\r\n",
      "End of epoch 182 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0000356 -> 0.0000337\r\n",
      "(epoch: 183, iters: 288, time: 0.024, data: 0.013) G_GAN: 1.266 G_L1: 21.158 D_real: 0.373 D_fake: 0.343 \r\n",
      "End of epoch 183 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0000337 -> 0.0000317\r\n",
      "End of epoch 184 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0000317 -> 0.0000297\r\n",
      "(epoch: 185, iters: 256, time: 0.053, data: 0.013) G_GAN: 1.379 G_L1: 20.417 D_real: 0.522 D_fake: 0.259 \r\n",
      "saving the model at the end of epoch 185, iters 76960\r\n",
      "End of epoch 185 / 200 \t Time Taken: 7 sec\r\n",
      "learning rate 0.0000297 -> 0.0000277\r\n",
      "End of epoch 186 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0000277 -> 0.0000257\r\n",
      "(epoch: 187, iters: 224, time: 0.032, data: 0.015) G_GAN: 1.394 G_L1: 21.881 D_real: 0.240 D_fake: 0.345 \r\n",
      "End of epoch 187 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0000257 -> 0.0000238\r\n",
      "End of epoch 188 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0000238 -> 0.0000218\r\n",
      "(epoch: 189, iters: 192, time: 0.029, data: 0.016) G_GAN: 1.285 G_L1: 21.176 D_real: 0.254 D_fake: 0.419 \r\n",
      "End of epoch 189 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0000218 -> 0.0000198\r\n",
      "saving the model at the end of epoch 190, iters 79040\r\n",
      "End of epoch 190 / 200 \t Time Taken: 6 sec\r\n",
      "learning rate 0.0000198 -> 0.0000178\r\n",
      "(epoch: 191, iters: 160, time: 0.028, data: 0.013) G_GAN: 1.327 G_L1: 21.038 D_real: 0.273 D_fake: 0.365 \r\n",
      "End of epoch 191 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0000178 -> 0.0000158\r\n",
      "End of epoch 192 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0000158 -> 0.0000139\r\n",
      "(epoch: 193, iters: 128, time: 0.031, data: 0.015) G_GAN: 1.114 G_L1: 22.241 D_real: 0.204 D_fake: 0.521 \r\n",
      "saving the latest model (epoch 193, total_iters 80000)\r\n",
      "End of epoch 193 / 200 \t Time Taken: 5 sec\r\n",
      "learning rate 0.0000139 -> 0.0000119\r\n",
      "End of epoch 194 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0000119 -> 0.0000099\r\n",
      "(epoch: 195, iters: 96, time: 0.044, data: 0.018) G_GAN: 1.122 G_L1: 21.049 D_real: 0.348 D_fake: 0.457 \r\n",
      "saving the model at the end of epoch 195, iters 81120\r\n",
      "End of epoch 195 / 200 \t Time Taken: 7 sec\r\n",
      "learning rate 0.0000099 -> 0.0000079\r\n",
      "End of epoch 196 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0000079 -> 0.0000059\r\n",
      "(epoch: 197, iters: 64, time: 0.028, data: 0.016) G_GAN: 1.080 G_L1: 21.825 D_real: 0.330 D_fake: 0.486 \r\n",
      "End of epoch 197 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0000059 -> 0.0000040\r\n",
      "End of epoch 198 / 200 \t Time Taken: 3 sec\r\n",
      "learning rate 0.0000040 -> 0.0000020\r\n",
      "(epoch: 199, iters: 32, time: 0.027, data: 0.012) G_GAN: 1.485 G_L1: 20.710 D_real: 0.686 D_fake: 0.290 \r\n",
      "End of epoch 199 / 200 \t Time Taken: 4 sec\r\n",
      "learning rate 0.0000020 -> 0.0000000\r\n",
      "(epoch: 200, iters: 416, time: 0.037, data: 0.012) G_GAN: 1.065 G_L1: 22.001 D_real: 0.450 D_fake: 0.481 \r\n",
      "saving the model at the end of epoch 200, iters 83200\r\n",
      "End of epoch 200 / 200 \t Time Taken: 8 sec\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA --display_id 1 --gpu_ids 0 --batch_size 32"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-06T11:43:56.792982Z",
     "end_time": "2023-10-06T12:00:39.176980Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UkcaFZiyASl"
   },
   "source": [
    "# Testing\n",
    "\n",
    "-   `python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix`\n",
    "\n",
    "Change the `--dataroot`, `--name`, and `--direction` to be consistent with your trained model's configuration and how you want to transform images.\n",
    "\n",
    "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
    "> Note that we specified --direction BtoA as Facades dataset's A to B direction is photos to labels.\n",
    "\n",
    "> If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use --model test option. See ./scripts/test_single.sh for how to apply a model to Facade label maps (stored in the directory facades/testB).\n",
    "\n",
    "> See a list of currently available models at ./scripts/download_pix2pix_model.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mey7o6j-0368",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1696339013320,
     "user_tz": -480,
     "elapsed": 428,
     "user": {
      "displayName": "Catniss Cullen",
      "userId": "16439932022125892298"
     }
    },
    "outputId": "aa0924df-0b77-4f80-983e-0267fe5dcf21",
    "ExecuteTime": {
     "start_time": "2023-10-06T16:15:39.122312Z",
     "end_time": "2023-10-06T16:15:39.252256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day2night_pretrained\tfacades_label2photo_pretrained\tmap2sat_pretrained\r\n",
      "edges2shoes_pretrained\tfacades_pix2pix\r\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/gpu/.netrc\r\n"
     ]
    }
   ],
   "source": [
    "!wandb login 0dc224c675c9a31cabfefec19ee2d54cca10e1d2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-06T16:15:41.115041Z",
     "end_time": "2023-10-06T16:15:42.743597Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\r\n",
      "             aspect_ratio: 1.0                           \r\n",
      "               batch_size: 1                             \r\n",
      "          checkpoints_dir: ./checkpoints                 \r\n",
      "                crop_size: 256                           \r\n",
      "                 dataroot: ./datasets/facades            \t[default: None]\r\n",
      "             dataset_mode: aligned                       \r\n",
      "                direction: BtoA                          \t[default: AtoB]\r\n",
      "          display_winsize: 256                           \r\n",
      "                    epoch: latest                        \r\n",
      "                     eval: False                         \r\n",
      "                  gpu_ids: 0                             \r\n",
      "                init_gain: 0.02                          \r\n",
      "                init_type: normal                        \r\n",
      "                 input_nc: 3                             \r\n",
      "                  isTrain: False                         \t[default: None]\r\n",
      "                load_iter: 0                             \t[default: 0]\r\n",
      "                load_size: 256                           \r\n",
      "         max_dataset_size: inf                           \r\n",
      "                    model: pix2pix                       \t[default: test]\r\n",
      "               n_layers_D: 3                             \r\n",
      "                     name: facades_pix2pix               \t[default: experiment_name]\r\n",
      "                      ndf: 64                            \r\n",
      "                     netD: basic                         \r\n",
      "                     netG: unet_256                      \r\n",
      "                      ngf: 64                            \r\n",
      "               no_dropout: False                         \r\n",
      "                  no_flip: False                         \r\n",
      "                     norm: batch                         \r\n",
      "                 num_test: 50                            \r\n",
      "              num_threads: 4                             \r\n",
      "                output_nc: 3                             \r\n",
      "                    phase: test                          \r\n",
      "               preprocess: resize_and_crop               \r\n",
      "              results_dir: ./results/                    \r\n",
      "           serial_batches: False                         \r\n",
      "                   suffix:                               \r\n",
      "                use_wandb: True                          \t[default: False]\r\n",
      "                  verbose: True                          \t[default: False]\r\n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \r\n",
      "----------------- End -------------------\r\n",
      "dataset [AlignedDataset] was created\r\n",
      "initialize network with normal\r\n",
      "model [Pix2PixModel] was created\r\n",
      "loading the model from ./checkpoints/facades_pix2pix/latest_net_G.pth\r\n",
      "---------- Networks initialized -------------\r\n",
      "DataParallel(\r\n",
      "  (module): UnetGenerator(\r\n",
      "    (model): UnetSkipConnectionBlock(\r\n",
      "      (model): Sequential(\r\n",
      "        (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "        (1): UnetSkipConnectionBlock(\r\n",
      "          (model): Sequential(\r\n",
      "            (0): LeakyReLU(negative_slope=0.2, inplace=True)\r\n",
      "            (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (3): UnetSkipConnectionBlock(\r\n",
      "              (model): Sequential(\r\n",
      "                (0): LeakyReLU(negative_slope=0.2, inplace=True)\r\n",
      "                (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "                (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (3): UnetSkipConnectionBlock(\r\n",
      "                  (model): Sequential(\r\n",
      "                    (0): LeakyReLU(negative_slope=0.2, inplace=True)\r\n",
      "                    (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "                    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                    (3): UnetSkipConnectionBlock(\r\n",
      "                      (model): Sequential(\r\n",
      "                        (0): LeakyReLU(negative_slope=0.2, inplace=True)\r\n",
      "                        (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "                        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                        (3): UnetSkipConnectionBlock(\r\n",
      "                          (model): Sequential(\r\n",
      "                            (0): LeakyReLU(negative_slope=0.2, inplace=True)\r\n",
      "                            (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "                            (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                            (3): UnetSkipConnectionBlock(\r\n",
      "                              (model): Sequential(\r\n",
      "                                (0): LeakyReLU(negative_slope=0.2, inplace=True)\r\n",
      "                                (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "                                (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                                (3): UnetSkipConnectionBlock(\r\n",
      "                                  (model): Sequential(\r\n",
      "                                    (0): LeakyReLU(negative_slope=0.2, inplace=True)\r\n",
      "                                    (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "                                    (2): ReLU(inplace=True)\r\n",
      "                                    (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "                                    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                                  )\r\n",
      "                                )\r\n",
      "                                (4): ReLU(inplace=True)\r\n",
      "                                (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "                                (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                                (7): Dropout(p=0.5, inplace=False)\r\n",
      "                              )\r\n",
      "                            )\r\n",
      "                            (4): ReLU(inplace=True)\r\n",
      "                            (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "                            (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                            (7): Dropout(p=0.5, inplace=False)\r\n",
      "                          )\r\n",
      "                        )\r\n",
      "                        (4): ReLU(inplace=True)\r\n",
      "                        (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "                        (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                        (7): Dropout(p=0.5, inplace=False)\r\n",
      "                      )\r\n",
      "                    )\r\n",
      "                    (4): ReLU(inplace=True)\r\n",
      "                    (5): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "                    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                  )\r\n",
      "                )\r\n",
      "                (4): ReLU(inplace=True)\r\n",
      "                (5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "                (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (4): ReLU(inplace=True)\r\n",
      "            (5): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "            (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (2): ReLU(inplace=True)\r\n",
      "        (3): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\r\n",
      "        (4): Tanh()\r\n",
      "      )\r\n",
      "    )\r\n",
      "  )\r\n",
      ")\r\n",
      "[Network G] Total number of parameters : 54.414 M\r\n",
      "-----------------------------------------------\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Tracking run with wandb version 0.15.12\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: W&B syncing is set to \u001B[1m`offline`\u001B[0m in this directory.  \r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run \u001B[1m`wandb online`\u001B[0m or set \u001B[1mWANDB_MODE=online\u001B[0m to enable cloud syncing.\r\n",
      "creating web directory ./results/facades_pix2pix/test_latest\r\n",
      "processing (0000)-th image... ['./datasets/facades/test/1.jpg']\r\n",
      "processing (0005)-th image... ['./datasets/facades/test/103.jpg']\r\n",
      "processing (0010)-th image... ['./datasets/facades/test/12.jpg']\r\n",
      "processing (0015)-th image... ['./datasets/facades/test/17.jpg']\r\n",
      "processing (0020)-th image... ['./datasets/facades/test/21.jpg']\r\n",
      "processing (0025)-th image... ['./datasets/facades/test/26.jpg']\r\n",
      "processing (0030)-th image... ['./datasets/facades/test/30.jpg']\r\n",
      "processing (0035)-th image... ['./datasets/facades/test/35.jpg']\r\n",
      "processing (0040)-th image... ['./datasets/facades/test/4.jpg']\r\n",
      "processing (0045)-th image... ['./datasets/facades/test/44.jpg']\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Waiting for W&B process to finish... \u001B[32m(success).\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: You can sync this run to the cloud by running:\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[1mwandb sync /data/ypq/PIX2PIX_CycleGAN/pytorch-cyclegan-and-pix2pix_fork/wandb/offline-run-20231006_162603-z68wuih8\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Find logs at: \u001B[35m\u001B[1m./wandb/offline-run-20231006_162603-z68wuih8/logs\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix --use_wandb --verbose"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-06T16:26:23.976313Z",
     "end_time": "2023-10-06T16:26:43.492706Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find logs at: /data/ypq/PIX2PIX_CycleGAN/pytorch-cyclegan-and-pix2pix_fork/wandb/debug-cli.gpu.log\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Network error (ProxyError), entering retry loop.\r\n",
      "^C\r\n",
      "\r\n",
      "Aborted!\r\n"
     ]
    }
   ],
   "source": [
    "!wandb sync /data/ypq/PIX2PIX_CycleGAN/pytorch-cyclegan-and-pix2pix_fork/wandb/offline-run-20231006_162127-clbg7le1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-06T16:28:15.451168Z",
     "end_time": "2023-10-06T16:28:24.149610Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints\tdocs\t\t models\t\tREADME.md\t  test.py\r\n",
      "CycleGAN.ipynb\tenvironment.yml  nohup.out\trequirements.txt  train.py\r\n",
      "data\t\timgs\t\t options\tresults\t\t  util\r\n",
      "datasets\tLICENSE\t\t pix2pix.ipynb\tscripts\t\t  wandb\r\n",
      "2023-10-06 16:26:03,458 INFO    MainThread:1998577 [wandb_setup.py:_flush():76] Current SDK version is 0.15.12\r\n",
      "2023-10-06 16:26:03,459 INFO    MainThread:1998577 [wandb_setup.py:_flush():76] Configure stats pid to 1998577\r\n",
      "2023-10-06 16:26:03,459 INFO    MainThread:1998577 [wandb_setup.py:_flush():76] Loading settings from /home/gpu/.config/wandb/settings\r\n",
      "2023-10-06 16:26:03,459 INFO    MainThread:1998577 [wandb_setup.py:_flush():76] Loading settings from /data/ypq/PIX2PIX_CycleGAN/pytorch-cyclegan-and-pix2pix_fork/wandb/settings\r\n",
      "2023-10-06 16:26:03,459 INFO    MainThread:1998577 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'api_key': '***REDACTED***', 'mode': 'offline'}\r\n",
      "2023-10-06 16:26:03,459 INFO    MainThread:1998577 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}\r\n",
      "2023-10-06 16:26:03,459 INFO    MainThread:1998577 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'test.py', 'program_abspath': '/data/ypq/PIX2PIX_CycleGAN/pytorch-cyclegan-and-pix2pix_fork/test.py', 'program': 'test.py'}\r\n",
      "2023-10-06 16:26:03,459 INFO    MainThread:1998577 [wandb_init.py:_log_setup():528] Logging user logs to /data/ypq/PIX2PIX_CycleGAN/pytorch-cyclegan-and-pix2pix_fork/wandb/offline-run-20231006_162603-z68wuih8/logs/debug.log\r\n",
      "2023-10-06 16:26:03,459 INFO    MainThread:1998577 [wandb_init.py:_log_setup():529] Logging internal logs to /data/ypq/PIX2PIX_CycleGAN/pytorch-cyclegan-and-pix2pix_fork/wandb/offline-run-20231006_162603-z68wuih8/logs/debug-internal.log\r\n",
      "2023-10-06 16:26:03,459 INFO    MainThread:1998577 [wandb_init.py:init():568] calling init triggers\r\n",
      "2023-10-06 16:26:03,459 INFO    MainThread:1998577 [wandb_init.py:init():575] wandb.init called with sweep_config: {}\r\n",
      "config: {'dataroot': './datasets/facades', 'name': 'facades_pix2pix', 'gpu_ids': [0], 'checkpoints_dir': './checkpoints', 'model': 'pix2pix', 'input_nc': 3, 'output_nc': 3, 'ngf': 64, 'ndf': 64, 'netD': 'basic', 'netG': 'unet_256', 'n_layers_D': 3, 'norm': 'batch', 'init_type': 'normal', 'init_gain': 0.02, 'no_dropout': False, 'dataset_mode': 'aligned', 'direction': 'BtoA', 'serial_batches': True, 'num_threads': 0, 'batch_size': 1, 'load_size': 256, 'crop_size': 256, 'max_dataset_size': inf, 'preprocess': 'resize_and_crop', 'no_flip': True, 'display_winsize': 256, 'epoch': 'latest', 'load_iter': 0, 'verbose': True, 'suffix': '', 'use_wandb': True, 'wandb_project_name': 'CycleGAN-and-pix2pix', 'results_dir': './results/', 'aspect_ratio': 1.0, 'phase': 'test', 'eval': False, 'num_test': 50, 'isTrain': False, 'display_id': -1}\r\n",
      "2023-10-06 16:26:03,459 INFO    MainThread:1998577 [wandb_init.py:init():618] starting backend\r\n",
      "2023-10-06 16:26:03,459 INFO    MainThread:1998577 [wandb_init.py:init():622] setting up manager\r\n",
      "2023-10-06 16:26:03,461 INFO    MainThread:1998577 [wandb_init.py:init():628] backend started and connected\r\n",
      "2023-10-06 16:26:03,465 INFO    MainThread:1998577 [wandb_init.py:init():720] updated telemetry\r\n",
      "2023-10-06 16:26:03,465 INFO    MainThread:1998577 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout\r\n",
      "2023-10-06 16:26:03,481 INFO    MainThread:1998577 [wandb_init.py:init():804] starting run threads in backend\r\n",
      "2023-10-06 16:26:06,690 INFO    MainThread:1998577 [wandb_run.py:_console_start():2199] atexit reg\r\n",
      "2023-10-06 16:26:06,690 INFO    MainThread:1998577 [wandb_run.py:_redirect():2054] redirect: wrap_raw\r\n",
      "2023-10-06 16:26:06,690 INFO    MainThread:1998577 [wandb_run.py:_redirect():2119] Wrapping output streams.\r\n",
      "2023-10-06 16:26:06,690 INFO    MainThread:1998577 [wandb_run.py:_redirect():2144] Redirects installed.\r\n",
      "2023-10-06 16:26:06,692 INFO    MainThread:1998577 [wandb_init.py:init():845] run started, returning control to user process\r\n",
      "2023-10-06 16:26:16,737 WARNING MsgRouterThr:1998577 [router.py:message_loop():77] message_loop has been closed\r\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "!cat  wandb/offline-run-20231006_162603-z68wuih8/logs/debug.log"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-06T16:35:45.635233Z",
     "end_time": "2023-10-06T16:35:45.927516Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzSKIPUByfiN"
   },
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "9Mgg8raPyizq"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mstyle\u001B[38;5;241m.\u001B[39muse(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mUsers\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mchael\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m.matplotlib\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mviolet.mplstyle\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      5\u001B[0m img \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39mimread(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./results/facades_label2photo_pretrained/test_latest/images/100_fake_B.png\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_fake_B.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0G3oVH9DyqLQ"
   },
   "outputs": [],
   "source": [
    "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_A.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ErK5OC1j1LH4"
   },
   "outputs": [],
   "source": [
    "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_B.png')\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "environment": {
   "name": "tf2-gpu.2-3.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
